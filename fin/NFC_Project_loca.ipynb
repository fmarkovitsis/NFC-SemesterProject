{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a7191f46",
      "metadata": {
        "id": "a7191f46"
      },
      "source": [
        "# Neuro-Fuzzy Computing - Project - Fall 2025\n",
        "## Galaxy Zoo — Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ZXkCrsacWoK",
      "metadata": {
        "id": "7ZXkCrsacWoK"
      },
      "source": [
        "#### Inspecting the initial dataset location"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vc0okI5GXiko",
      "metadata": {
        "id": "vc0okI5GXiko"
      },
      "source": [
        "### Dataset inspection and preprocessing\n",
        "\n",
        "In the following cells we perform the essential preprocessing steps\n",
        "\n",
        "1. **Define data paths and parameters**\n",
        "   - Point to the processed training images folder: `images_training_rev1/`\n",
        "   - Point to the label file: `training_solutions_rev1.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a9d49936",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1d17eba",
      "metadata": {},
      "source": [
        "Name of the root directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8kPAa1SRIwef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kPAa1SRIwef",
        "outputId": "a1ee2f40-ba0b-4cd5-cae2-a1ec49b3afd1"
      },
      "outputs": [],
      "source": [
        "root_dir = Path(\"C:\\\\Users\\\\sol77\\\\galaxy-zoo-the-galaxy-challenge\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07076ad3",
      "metadata": {},
      "source": [
        "Name of the images directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0dd9af75",
      "metadata": {},
      "outputs": [],
      "source": [
        "img_dir = root_dir / \"images_training_rev1\\\\images_training_rev1\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "818e3c5a",
      "metadata": {},
      "source": [
        "Path to the csv solutions file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "37e0b744",
      "metadata": {},
      "outputs": [],
      "source": [
        "csv_path = root_dir / \"training_solutions_rev1\\\\training_solutions_rev1.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6a0d556",
      "metadata": {},
      "source": [
        "Checking the validity of the given paths:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "462a191a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "img_dir exists: True\n",
            "csv_path exists: True\n"
          ]
        }
      ],
      "source": [
        "print(\"img_dir exists:\", img_dir.is_dir())\n",
        "print(\"csv_path exists:\", csv_path.is_file())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4K6EFxJqdDdj",
      "metadata": {
        "id": "4K6EFxJqdDdj"
      },
      "source": [
        "2. **Check label to image consistency**\n",
        "   - Confirm the number of label rows matches the number of processed images\n",
        "   - If there is a mismatch, we report example GalaxyIDs whose image files are missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8YpWNd3ydH8t",
      "metadata": {
        "id": "8YpWNd3ydH8t"
      },
      "outputs": [],
      "source": [
        "solutions_df = pd.read_csv(csv_path)\n",
        "\n",
        "ids = solutions_df[\"GalaxyID\"].astype(str).tolist()\n",
        "train_image_names = sorted([p.name for p in img_dir.glob(\"*.jpg\")])\n",
        "\n",
        "if len(ids) != len(train_image_names):\n",
        "    missing = []\n",
        "\n",
        "    for gid in ids:\n",
        "        if f\"{gid}.jpg\" not in name_set:\n",
        "            missing.append(gid)\n",
        "            \n",
        "    print (f\"Label/image count mismatch: labels={len(ids)} images={len(train_image_names)}. Missing images IDs stored in the 'missing' list\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2996c865",
      "metadata": {},
      "source": [
        "Secondly, making sure that all images are of the same size: 424x424"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4351a787",
      "metadata": {},
      "outputs": [],
      "source": [
        "for name in train_image_names:\n",
        "    with Image.open(img_dir / name) as img:\n",
        "        w, h = img.size\n",
        "        if w != 424 or h != 424:\n",
        "            print (f\"Size not 424x424 (image: {name})\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "La2fbyZqk_Zl",
      "metadata": {
        "id": "La2fbyZqk_Zl"
      },
      "source": [
        "3. **Prepare inputs for a TensorFlow dataset**\n",
        "\n",
        "In this cell, we:\n",
        "   - Create `paths` (image filepaths) and `labels` (soft targets) from `training_solutions_rev1.csv`\n",
        "   - Define `load_image(path, y)`, which will be used later with `tf.data.Dataset.map(...)` to load/parse images **on demand**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0b261cde",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GalaxyID</th>\n",
              "      <th>Class1.1</th>\n",
              "      <th>Class1.2</th>\n",
              "      <th>Class1.3</th>\n",
              "      <th>Class2.1</th>\n",
              "      <th>Class2.2</th>\n",
              "      <th>Class3.1</th>\n",
              "      <th>Class3.2</th>\n",
              "      <th>Class4.1</th>\n",
              "      <th>Class4.2</th>\n",
              "      <th>...</th>\n",
              "      <th>Class9.3</th>\n",
              "      <th>Class10.1</th>\n",
              "      <th>Class10.2</th>\n",
              "      <th>Class10.3</th>\n",
              "      <th>Class11.1</th>\n",
              "      <th>Class11.2</th>\n",
              "      <th>Class11.3</th>\n",
              "      <th>Class11.4</th>\n",
              "      <th>Class11.5</th>\n",
              "      <th>Class11.6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100008</td>\n",
              "      <td>0.383147</td>\n",
              "      <td>0.616853</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.616853</td>\n",
              "      <td>0.038452</td>\n",
              "      <td>0.578401</td>\n",
              "      <td>0.418398</td>\n",
              "      <td>0.198455</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.279952</td>\n",
              "      <td>0.138445</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.092886</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.325512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100023</td>\n",
              "      <td>0.327001</td>\n",
              "      <td>0.663777</td>\n",
              "      <td>0.009222</td>\n",
              "      <td>0.031178</td>\n",
              "      <td>0.632599</td>\n",
              "      <td>0.467370</td>\n",
              "      <td>0.165229</td>\n",
              "      <td>0.591328</td>\n",
              "      <td>0.041271</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018764</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131378</td>\n",
              "      <td>0.459950</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.591328</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100053</td>\n",
              "      <td>0.765717</td>\n",
              "      <td>0.177352</td>\n",
              "      <td>0.056931</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.177352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.177352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.177352</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100078</td>\n",
              "      <td>0.693377</td>\n",
              "      <td>0.238564</td>\n",
              "      <td>0.068059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.238564</td>\n",
              "      <td>0.109493</td>\n",
              "      <td>0.129071</td>\n",
              "      <td>0.189098</td>\n",
              "      <td>0.049466</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.094549</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.094549</td>\n",
              "      <td>0.189098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100090</td>\n",
              "      <td>0.933839</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066161</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   GalaxyID  Class1.1  Class1.2  Class1.3  Class2.1  Class2.2  Class3.1  \\\n",
              "0    100008  0.383147  0.616853  0.000000  0.000000  0.616853  0.038452   \n",
              "1    100023  0.327001  0.663777  0.009222  0.031178  0.632599  0.467370   \n",
              "2    100053  0.765717  0.177352  0.056931  0.000000  0.177352  0.000000   \n",
              "3    100078  0.693377  0.238564  0.068059  0.000000  0.238564  0.109493   \n",
              "4    100090  0.933839  0.000000  0.066161  0.000000  0.000000  0.000000   \n",
              "\n",
              "   Class3.2  Class4.1  Class4.2  ...  Class9.3  Class10.1  Class10.2  \\\n",
              "0  0.578401  0.418398  0.198455  ...  0.000000   0.279952   0.138445   \n",
              "1  0.165229  0.591328  0.041271  ...  0.018764   0.000000   0.131378   \n",
              "2  0.177352  0.000000  0.177352  ...  0.000000   0.000000   0.000000   \n",
              "3  0.129071  0.189098  0.049466  ...  0.000000   0.094549   0.000000   \n",
              "4  0.000000  0.000000  0.000000  ...  0.000000   0.000000   0.000000   \n",
              "\n",
              "   Class10.3  Class11.1  Class11.2  Class11.3  Class11.4  Class11.5  Class11.6  \n",
              "0   0.000000   0.000000   0.092886        0.0        0.0        0.0   0.325512  \n",
              "1   0.459950   0.000000   0.591328        0.0        0.0        0.0   0.000000  \n",
              "2   0.000000   0.000000   0.000000        0.0        0.0        0.0   0.000000  \n",
              "3   0.094549   0.189098   0.000000        0.0        0.0        0.0   0.000000  \n",
              "4   0.000000   0.000000   0.000000        0.0        0.0        0.0   0.000000  \n",
              "\n",
              "[5 rows x 38 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "solutions_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "282431b1",
      "metadata": {},
      "source": [
        "It is seen that solutions_df contains the GalaxyID. GalaxyID is not a target value and we should remove it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2bcdeebf",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class1.1</th>\n",
              "      <th>Class1.2</th>\n",
              "      <th>Class1.3</th>\n",
              "      <th>Class2.1</th>\n",
              "      <th>Class2.2</th>\n",
              "      <th>Class3.1</th>\n",
              "      <th>Class3.2</th>\n",
              "      <th>Class4.1</th>\n",
              "      <th>Class4.2</th>\n",
              "      <th>Class5.1</th>\n",
              "      <th>...</th>\n",
              "      <th>Class9.3</th>\n",
              "      <th>Class10.1</th>\n",
              "      <th>Class10.2</th>\n",
              "      <th>Class10.3</th>\n",
              "      <th>Class11.1</th>\n",
              "      <th>Class11.2</th>\n",
              "      <th>Class11.3</th>\n",
              "      <th>Class11.4</th>\n",
              "      <th>Class11.5</th>\n",
              "      <th>Class11.6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.383147</td>\n",
              "      <td>0.616853</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.616853</td>\n",
              "      <td>0.038452</td>\n",
              "      <td>0.578401</td>\n",
              "      <td>0.418398</td>\n",
              "      <td>0.198455</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.279952</td>\n",
              "      <td>0.138445</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.092886</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.325512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.327001</td>\n",
              "      <td>0.663777</td>\n",
              "      <td>0.009222</td>\n",
              "      <td>0.031178</td>\n",
              "      <td>0.632599</td>\n",
              "      <td>0.467370</td>\n",
              "      <td>0.165229</td>\n",
              "      <td>0.591328</td>\n",
              "      <td>0.041271</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018764</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.131378</td>\n",
              "      <td>0.459950</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.591328</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.765717</td>\n",
              "      <td>0.177352</td>\n",
              "      <td>0.056931</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.177352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.177352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.177352</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.693377</td>\n",
              "      <td>0.238564</td>\n",
              "      <td>0.068059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.238564</td>\n",
              "      <td>0.109493</td>\n",
              "      <td>0.129071</td>\n",
              "      <td>0.189098</td>\n",
              "      <td>0.049466</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.094549</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.094549</td>\n",
              "      <td>0.189098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.933839</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066161</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 37 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Class1.1  Class1.2  Class1.3  Class2.1  Class2.2  Class3.1  Class3.2  \\\n",
              "0  0.383147  0.616853  0.000000  0.000000  0.616853  0.038452  0.578401   \n",
              "1  0.327001  0.663777  0.009222  0.031178  0.632599  0.467370  0.165229   \n",
              "2  0.765717  0.177352  0.056931  0.000000  0.177352  0.000000  0.177352   \n",
              "3  0.693377  0.238564  0.068059  0.000000  0.238564  0.109493  0.129071   \n",
              "4  0.933839  0.000000  0.066161  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "   Class4.1  Class4.2  Class5.1  ...  Class9.3  Class10.1  Class10.2  \\\n",
              "0  0.418398  0.198455       0.0  ...  0.000000   0.279952   0.138445   \n",
              "1  0.591328  0.041271       0.0  ...  0.018764   0.000000   0.131378   \n",
              "2  0.000000  0.177352       0.0  ...  0.000000   0.000000   0.000000   \n",
              "3  0.189098  0.049466       0.0  ...  0.000000   0.094549   0.000000   \n",
              "4  0.000000  0.000000       0.0  ...  0.000000   0.000000   0.000000   \n",
              "\n",
              "   Class10.3  Class11.1  Class11.2  Class11.3  Class11.4  Class11.5  Class11.6  \n",
              "0   0.000000   0.000000   0.092886        0.0        0.0        0.0   0.325512  \n",
              "1   0.459950   0.000000   0.591328        0.0        0.0        0.0   0.000000  \n",
              "2   0.000000   0.000000   0.000000        0.0        0.0        0.0   0.000000  \n",
              "3   0.094549   0.189098   0.000000        0.0        0.0        0.0   0.000000  \n",
              "4   0.000000   0.000000   0.000000        0.0        0.0        0.0   0.000000  \n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_cols = solutions_df.drop(\"GalaxyID\", axis=1)\n",
        "target_cols.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a8814ab1",
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = target_cols.to_numpy(dtype=\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8866f4b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.Resize((424, 424), interpolation=transforms.InterpolationMode.LANCZOS),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def load_image(img_dir, path, y):\n",
        "    img = Image.open(img_dir / path).convert(\"RGB\")\n",
        "    img = img_transform(img)  # float32, [0,1], shape [3,424,424]\n",
        "    y = torch.as_tensor(y, dtype=torch.float32)\n",
        "    return img, y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CcWh08yqiBLU",
      "metadata": {
        "id": "CcWh08yqiBLU"
      },
      "source": [
        "### Train/Val/Test split (80/10/10)\n",
        "\n",
        "We create our own 80/10/10 train/val/test split from the edited training set.\n",
        "\n",
        "We start from a dataset of `(filepath, target_vector)` pairs and we shuffle **once** with a fixed seed (`seed=42`, `reshuffle_each_iteration=False`) to get a reproducible, **fixed** random ordering\n",
        "\n",
        "Split by slicing the shuffled dataset:\n",
        "  - **Train:** first 80% of samples\n",
        "  - **Validation:** next 10%\n",
        "  - **Test:** final 10%\n",
        "\n",
        "Lastly, we apply `load_image` **after** the split so each subset loads/decodes images lazily and independently"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d992de45",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size: 61578\n",
            "Train: 49262\n",
            "Val: 6157\n",
            "Test: 6159\n"
          ]
        }
      ],
      "source": [
        "n_total = len(train_image_names)\n",
        "n_train = int(0.8 * n_total)\n",
        "n_val   = int(0.1 * n_total)\n",
        "n_test  = n_total - n_train - n_val\n",
        "\n",
        "print(\"Dataset size:\", n_total)\n",
        "print(\"Train:\", n_train)\n",
        "print(\"Val:\", n_val)\n",
        "print(\"Test:\", n_test)\n",
        "\n",
        "# Shuffle once\n",
        "g = torch.Generator().manual_seed(42)\n",
        "perm = torch.randperm(n_total, generator=g).numpy()\n",
        "\n",
        "train_image_names = np.array(train_image_names)\n",
        "paths_shuf  = train_image_names[perm]\n",
        "labels_shuf = labels[perm]\n",
        "\n",
        "# Split\n",
        "train_paths, train_labels = paths_shuf[:n_train], labels_shuf[:n_train]\n",
        "val_paths,   val_labels   = paths_shuf[n_train:n_train + n_val], labels_shuf[n_train:n_train + n_val]\n",
        "test_paths,  test_labels  = paths_shuf[n_train + n_val:], labels_shuf[n_train + n_val:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hIYiScOSj5nI",
      "metadata": {
        "id": "hIYiScOSj5nI"
      },
      "source": [
        "### Image loading pipeline (lazy + batched)\n",
        "\n",
        "To build the dataset, we:\n",
        "   - Convert the split datasets from `(filepath, target_vector)` into `(image_tensor, target_tensor)` using `map(load_image)`\n",
        "     - Images are read/decoded **on demand** with `tf.io.read_file` + `tf.io.decode_jpeg`\n",
        "     - Converted to `float32` in **[0, 1]** (and resized to 424×424 as a safety step)\n",
        "   - Optimize input throughput:\n",
        "     - **Train:** shuffle (per epoch) → batch → prefetch\n",
        "     - **Val/Test:** batch → prefetch\n",
        "\n",
        "Each dataset element is a **batch** `(image_tensor, target_tensor)` where:\n",
        "  - `image_tensor` has shape **(batch_size, 424, 424, 3)** (channels-last) in **[0, 1]**\n",
        "  - `target_tensor` has shape **(batch_size, 37)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9Uir0aPYzZII",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Uir0aPYzZII",
        "outputId": "745a0fdc-ae4b-4878-e015-f6048086377a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train batch x: torch.Size([16, 3, 424, 424]) torch.float32 y: torch.Size([16, 37]) torch.float32\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "class PathLabelDataset(Dataset):\n",
        "    def __init__(self, img_dir, paths, labels):\n",
        "        self.paths = paths\n",
        "        self.labels = labels\n",
        "        self.img_dir = img_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return load_image(self.img_dir, self.paths[idx], self.labels[idx])\n",
        "\n",
        "train_dataset = PathLabelDataset(img_dir, train_paths, train_labels)\n",
        "val_dataset   = PathLabelDataset(img_dir, val_paths, val_labels)\n",
        "test_dataset  = PathLabelDataset(img_dir, test_paths, test_labels)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Estimate total steps (batches) for full training run\n",
        "steps_per_epoch = len(train_loader)\n",
        "total_steps = int(steps_per_epoch * 30)  # 30 = max epochs\n",
        "\n",
        "xb, yb = next(iter(train_loader))\n",
        "print(\"train batch x:\", xb.shape, xb.dtype, \"y:\", yb.shape, yb.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PJqOTcWOplDw",
      "metadata": {
        "id": "PJqOTcWOplDw"
      },
      "source": [
        "### Building our CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "nZd_Ydzmpnm3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "id": "nZd_Ydzmpnm3",
        "outputId": "fd42893a-6cd2-44cf-e369-d997a5562735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Dropout2d(p=0.05, inplace=False)\n",
            "  (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): ReLU(inplace=True)\n",
            "  (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (15): Dropout2d(p=0.1, inplace=False)\n",
            "  (16): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (17): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (18): ReLU(inplace=True)\n",
            "  (19): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (21): ReLU(inplace=True)\n",
            "  (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (23): Dropout2d(p=0.15, inplace=False)\n",
            "  (24): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (26): ReLU(inplace=True)\n",
            "  (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (29): ReLU(inplace=True)\n",
            "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (31): Dropout2d(p=0.2, inplace=False)\n",
            "  (32): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (33): Flatten(start_dim=1, end_dim=-1)\n",
            "  (34): Linear(in_features=256, out_features=37, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    # Block 1 (3 -> 32) with 2 convs\n",
        "    nn.Conv2d(3, 32, kernel_size=3, padding=1, bias=True),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=True),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Dropout2d(p=0.05),\n",
        "\n",
        "    # Block 2 (32 -> 64) with 2 convs\n",
        "    nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=True),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=True),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Dropout2d(p=0.10),\n",
        "\n",
        "    # Block 3 (64 -> 128) with 2 convs\n",
        "    nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=True),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=True),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Dropout2d(p=0.15),\n",
        "\n",
        "    # Block 4 (128 -> 256) with 2 convs\n",
        "    nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=True),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=True),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Dropout2d(p=0.20),\n",
        "\n",
        "    # Global average pooling + 37-dim output\n",
        "    nn.AdaptiveAvgPool2d((1, 1)),\n",
        "    nn.Flatten(1),\n",
        "    nn.Linear(256, 37, bias=True),\n",
        ")\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T8LHtZktsC_s",
      "metadata": {
        "id": "T8LHtZktsC_s"
      },
      "source": [
        "### Optimizer, loss function and model compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z6NfIzqHkWRQ",
      "metadata": {
        "id": "Z6NfIzqHkWRQ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "def cosine_decay(step: int, total_steps: int, initial_lr: float = 1e-3, alpha: float = 1e-2) -> float:\n",
        "    step = min(step, total_steps)\n",
        "    cosine = 0.5 * (1.0 + math.cos(math.pi * step / total_steps))\n",
        "    return initial_lr * (alpha + (1.0 - alpha) * cosine)\n",
        "\n",
        "def set_lr(optimizer: torch.optim.Optimizer, lr: float) -> None:\n",
        "    for pg in optimizer.param_groups:\n",
        "        pg[\"lr\"] = lr\n",
        "\n",
        "def get_current_lr(optimizer: torch.optim.Optimizer) -> float:\n",
        "    return float(optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "def rmse_sum_sse(pred: torch.Tensor, target: torch.Tensor) -> tuple[float, int]:\n",
        "    # returns (sum_squared_error, num_elements)\n",
        "    diff = pred - target\n",
        "    sse = float(torch.sum(diff * diff).detach().cpu().item())\n",
        "    n = target.numel()\n",
        "    return sse, n\n",
        "\n",
        "@torch.no_grad()\n",
        "def rmse(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DJBhN4TNtDti",
      "metadata": {
        "id": "DJBhN4TNtDti"
      },
      "source": [
        "### Defining the training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "Eb5ZfncXtF2t",
      "metadata": {
        "id": "Eb5ZfncXtF2t"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import copy\n",
        "import math\n",
        "import torch\n",
        "\n",
        "def train_loop(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs,\n",
        "    patience,\n",
        "    min_delta,\n",
        "    total_steps,\n",
        "    initial_lr,\n",
        "    alpha,\n",
        "    device,\n",
        "    criterion,\n",
        "    optimizer\n",
        "):\n",
        "\n",
        "    best_val = float(\"inf\")\n",
        "    patience_ctr = 0\n",
        "    best_state = None\n",
        "    global_step = 0\n",
        "    last_epoch = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        t0 = time.time()\n",
        "        last_epoch = epoch\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_sse = 0.0\n",
        "        train_n = 0\n",
        "\n",
        "        for xb, yb in train_loader:\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "            lr = cosine_decay(global_step, total_steps, initial_lr=initial_lr, alpha=alpha)\n",
        "            set_lr(optimizer, lr)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            preds = model(xb)\n",
        "            loss = criterion(preds, yb)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            sse, n = rmse_sum_sse(preds, yb)\n",
        "            train_sse += sse\n",
        "            train_n += n\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        train_rmse_val = math.sqrt(train_sse / max(1, train_n))\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        val_sse = 0.0\n",
        "        val_n = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb = xb.to(device, non_blocking=True)\n",
        "                yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "                preds = model(xb)\n",
        "\n",
        "                sse, n = rmse_sum_sse(preds, yb)\n",
        "                val_sse += sse\n",
        "                val_n += n\n",
        "\n",
        "        val_rmse_val = math.sqrt(val_sse / max(1, val_n))\n",
        "\n",
        "        lr_val = get_current_lr(optimizer)\n",
        "        dt = time.time() - t0\n",
        "\n",
        "        # Early stopping\n",
        "        improved = (best_val - val_rmse_val) > min_delta\n",
        "        if improved:\n",
        "            best_val = val_rmse_val\n",
        "            patience_ctr = 0\n",
        "            best_state = copy.deepcopy(model.state_dict())\n",
        "        else:\n",
        "            patience_ctr += 1\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:02d}/{epochs} | \"\n",
        "            f\"lr={lr_val:.6g} | \"\n",
        "            f\"train_RMSE={train_rmse_val:.6f} | \"\n",
        "            f\"eval_RMSE={val_rmse_val:.6f} | \"\n",
        "            f\"patience={patience_ctr}/{patience} | \"\n",
        "            f\"time={dt:.2f}s\"\n",
        "        )\n",
        "\n",
        "        if patience_ctr >= patience:\n",
        "            break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    return last_epoch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cErZXrGOvEbg",
      "metadata": {
        "id": "cErZXrGOvEbg"
      },
      "source": [
        "### Training our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "lq_yj1hwvHON",
      "metadata": {
        "id": "lq_yj1hwvHON"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sol77\\miniconda3\\envs\\ece352_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  super().__init__(loader)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m epochs_ran = \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mtrain_loop\u001b[39m\u001b[34m(model, train_loader, val_loader, epochs, patience, min_delta, total_steps, initial_lr, alpha, device, criterion, optimizer)\u001b[39m\n\u001b[32m     41\u001b[39m set_lr(optimizer, lr)\n\u001b[32m     43\u001b[39m optimizer.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m preds = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m loss = criterion(preds, yb)\n\u001b[32m     48\u001b[39m loss.backward()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sol77\\miniconda3\\envs\\ece352_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sol77\\miniconda3\\envs\\ece352_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sol77\\miniconda3\\envs\\ece352_env\\Lib\\site-packages\\torch\\nn\\modules\\container.py:253\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sol77\\miniconda3\\envs\\ece352_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sol77\\miniconda3\\envs\\ece352_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sol77\\miniconda3\\envs\\ece352_env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:553\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sol77\\miniconda3\\envs\\ece352_env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    537\u001b[39m         F.pad(\n\u001b[32m    538\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    545\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    546\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "epochs_ran = train_loop(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=30,\n",
        "    patience=3,\n",
        "    min_delta=1e-3,\n",
        "    total_steps=total_steps,\n",
        "    initial_lr=1e-3,\n",
        "    alpha=1e-2,\n",
        "    device=device,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PFUfJuPFxOtl",
      "metadata": {
        "id": "PFUfJuPFxOtl"
      },
      "source": [
        "### Evaluate on held-out test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nkPJqgQ6xLEO",
      "metadata": {
        "id": "nkPJqgQ6xLEO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test RMSE: 0.09789868925789266\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "test_sse = 0.0\n",
        "test_n = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "            preds = model(xb)\n",
        "\n",
        "        diff = preds - yb\n",
        "        test_sse += float(torch.sum(diff * diff).cpu().item())\n",
        "        test_n += yb.numel()\n",
        "\n",
        "test_rmse = math.sqrt(test_sse / max(1, test_n))\n",
        "print(\"Test RMSE:\", test_rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "eY6TqC9mSXdV",
      "metadata": {
        "id": "eY6TqC9mSXdV"
      },
      "outputs": [],
      "source": [
        "# Cell for cleanup\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ETngSJhzGhQC",
      "metadata": {
        "id": "ETngSJhzGhQC"
      },
      "source": [
        "## Comparison with other models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pr-qppS6GlCz",
      "metadata": {
        "id": "pr-qppS6GlCz"
      },
      "source": [
        "#### DenseNet\n",
        "\n",
        "##### Model build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "sv7dGOPBGr2O",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "sv7dGOPBGr2O",
        "outputId": "2fee6def-c76a-4373-997c-b7372becb8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /home/user/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): ImageClassification(\n",
            "      crop_size=[224]\n",
            "      resize_size=[256]\n",
            "      mean=[0.485, 0.456, 0.406]\n",
            "      std=[0.229, 0.224, 0.225]\n",
            "      interpolation=InterpolationMode.BILINEAR\n",
            "  )\n",
            "  (1): DenseNet(\n",
            "    (features): Sequential(\n",
            "      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU(inplace=True)\n",
            "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (denseblock1): _DenseBlock(\n",
            "        (denselayer1): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer2): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer3): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer4): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer5): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer6): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (transition1): _Transition(\n",
            "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      )\n",
            "      (denseblock2): _DenseBlock(\n",
            "        (denselayer1): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer2): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer3): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer4): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer5): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer6): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer7): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer8): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer9): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer10): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer11): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer12): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (transition2): _Transition(\n",
            "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      )\n",
            "      (denseblock3): _DenseBlock(\n",
            "        (denselayer1): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer2): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer3): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer4): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer5): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer6): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer7): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer8): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer9): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer10): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer11): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer12): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer13): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer14): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer15): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer16): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer17): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer18): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer19): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer20): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer21): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer22): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer23): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer24): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (transition3): _Transition(\n",
            "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      )\n",
            "      (denseblock4): _DenseBlock(\n",
            "        (denselayer1): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer2): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer3): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer4): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer5): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer6): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer7): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer8): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer9): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer10): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer11): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer12): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer13): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer14): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer15): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer16): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (classifier): Identity()\n",
            "  )\n",
            "  (2): Linear(in_features=1024, out_features=37, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "\n",
        "weights = models.DenseNet121_Weights.IMAGENET1K_V1\n",
        "base = models.densenet121(weights=weights)\n",
        "\n",
        "# Use as a feature extractor (remove classifier)\n",
        "base.classifier = nn.Identity()\n",
        "\n",
        "model2 = nn.Sequential(\n",
        "    weights.transforms(),      # handles resize/crop if needed + ImageNet normalization\n",
        "    base,                      # outputs [B, 1024]\n",
        "    nn.Linear(1024, 37, bias=True),\n",
        ")\n",
        "\n",
        "model2 = model2.to(device)\n",
        "\n",
        "print(model2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m6ci9DguH7OE",
      "metadata": {
        "id": "m6ci9DguH7OE"
      },
      "source": [
        "##### Compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "NJPBQ6-EH9gC",
      "metadata": {
        "id": "NJPBQ6-EH9gC"
      },
      "outputs": [],
      "source": [
        "model2 = model2.to(device)\n",
        "\n",
        "criterion2 = nn.MSELoss()\n",
        "\n",
        "optimizer2 = torch.optim.AdamW(model2.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "def cosine_decay2(step: int, total_steps: int, initial_lr: float = 1e-3, alpha: float = 1e-2) -> float:\n",
        "    step = min(step, total_steps)\n",
        "    cosine = 0.5 * (1.0 + math.cos(math.pi * step / total_steps))\n",
        "    return initial_lr * (alpha + (1.0 - alpha) * cosine)\n",
        "\n",
        "def set_lr2(optimizer: torch.optim.Optimizer, lr: float) -> None:\n",
        "    for pg in optimizer.param_groups:\n",
        "        pg[\"lr\"] = lr\n",
        "\n",
        "@torch.no_grad()\n",
        "def rmse2(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
        "\n",
        "scaler2 = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9i6tUumEIAnV",
      "metadata": {
        "id": "9i6tUumEIAnV"
      },
      "source": [
        "##### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "816e45cd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01/30 | lr=0.00099729 | train_RMSE=0.123484 | eval_RMSE=0.104466 | patience=0/3 | time=163.39s\n",
            "Epoch 02/30 | lr=0.000989187 | train_RMSE=0.104444 | eval_RMSE=0.100183 | patience=0/3 | time=162.76s\n",
            "Epoch 03/30 | lr=0.000975778 | train_RMSE=0.098061 | eval_RMSE=0.098982 | patience=0/3 | time=162.53s\n",
            "Epoch 04/30 | lr=0.000957212 | train_RMSE=0.092934 | eval_RMSE=0.092127 | patience=0/3 | time=163.21s\n",
            "Epoch 05/30 | lr=0.000933691 | train_RMSE=0.088679 | eval_RMSE=0.091321 | patience=1/3 | time=162.22s\n",
            "Epoch 06/30 | lr=0.000905473 | train_RMSE=0.085375 | eval_RMSE=0.087067 | patience=0/3 | time=162.51s\n",
            "Epoch 07/30 | lr=0.000872868 | train_RMSE=0.082520 | eval_RMSE=0.086000 | patience=0/3 | time=162.94s\n",
            "Epoch 08/30 | lr=0.000836232 | train_RMSE=0.080091 | eval_RMSE=0.084653 | patience=0/3 | time=162.55s\n",
            "Epoch 09/30 | lr=0.000795967 | train_RMSE=0.077301 | eval_RMSE=0.090185 | patience=1/3 | time=162.86s\n",
            "Epoch 10/30 | lr=0.000752515 | train_RMSE=0.074780 | eval_RMSE=0.086159 | patience=2/3 | time=162.63s\n",
            "Epoch 11/30 | lr=0.00070635 | train_RMSE=0.071841 | eval_RMSE=0.085086 | patience=3/3 | time=162.73s\n"
          ]
        }
      ],
      "source": [
        "epochs_ran2 = train_loop(\n",
        "    model2,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=30,\n",
        "    patience=3,\n",
        "    min_delta=1e-3,\n",
        "    total_steps=total_steps,\n",
        "    initial_lr=1e-3,\n",
        "    alpha=1e-2,\n",
        "    device=device,\n",
        "    criterion=criterion2,\n",
        "    optimizer=optimizer2,\n",
        "    scaler=scaler2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PTM07DDPIHES",
      "metadata": {
        "id": "PTM07DDPIHES"
      },
      "source": [
        "##### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iAj3xFyLIK_R",
      "metadata": {
        "id": "iAj3xFyLIK_R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DenseNet Test RMSE: 0.0847407106771224\n",
            "DenseNet epochs: 11\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "model2.eval()\n",
        "\n",
        "test_sse = 0.0\n",
        "test_n = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "            preds = model2(xb)\n",
        "\n",
        "        diff = preds - yb\n",
        "        test_sse += float(torch.sum(diff * diff).detach().cpu().item())\n",
        "        test_n += yb.numel()\n",
        "\n",
        "test_rmse2 = math.sqrt(test_sse / max(1, test_n))\n",
        "print(\"DenseNet Test RMSE:\", test_rmse2)\n",
        "print(\"DenseNet epochs:\", epochs_ran2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "R1CrVVmkTEMY",
      "metadata": {
        "id": "R1CrVVmkTEMY"
      },
      "outputs": [],
      "source": [
        "# Cell for cleanup\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B8Cv6GieIRPE",
      "metadata": {
        "id": "B8Cv6GieIRPE"
      },
      "source": [
        "#### ResNet\n",
        "##### Model build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "hztEfsKwIVXl",
      "metadata": {
        "id": "hztEfsKwIVXl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /home/user/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "  (1): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (2): Linear(in_features=2048, out_features=37, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torchvision.transforms import Normalize\n",
        "\n",
        "weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
        "base = models.resnet50(weights=weights)\n",
        "\n",
        "# Remove classification head so it outputs features\n",
        "base.fc = nn.Identity()\n",
        "\n",
        "imagenet_normalize = Normalize(\n",
        "    mean=(0.485, 0.456, 0.406),\n",
        "    std=(0.229, 0.224, 0.225),\n",
        ")\n",
        "\n",
        "model3 = nn.Sequential(\n",
        "    imagenet_normalize,      # expects float tensors in [0,1], shape [B,3,H,W]\n",
        "    base,                    # outputs [B, 2048]\n",
        "    nn.Linear(2048, 37, bias=True),\n",
        ")\n",
        "\n",
        "model3 = model3.to(device)\n",
        "\n",
        "print(model3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0g-8hUevIgSB",
      "metadata": {
        "id": "0g-8hUevIgSB"
      },
      "source": [
        "##### Compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "M1ghbesZI79p",
      "metadata": {
        "id": "M1ghbesZI79p"
      },
      "outputs": [],
      "source": [
        "criterion3 = nn.MSELoss()\n",
        "\n",
        "optimizer3 = torch.optim.AdamW(model3.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "def cosine_decay3(step: int, total_steps: int, initial_lr: float = 1e-3, alpha: float = 1e-2) -> float:\n",
        "    step = min(step, total_steps)\n",
        "    cosine = 0.5 * (1.0 + math.cos(math.pi * step / total_steps))\n",
        "    return initial_lr * (alpha + (1.0 - alpha) * cosine)\n",
        "\n",
        "def set_lr3(optimizer: torch.optim.Optimizer, lr: float) -> None:\n",
        "    for pg in optimizer.param_groups:\n",
        "        pg[\"lr\"] = lr\n",
        "\n",
        "@torch.no_grad()\n",
        "def rmse3(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
        "\n",
        "scaler3 = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j6OPEbqiIhyp",
      "metadata": {
        "id": "j6OPEbqiIhyp"
      },
      "source": [
        "##### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "RGoo99B_JA4N",
      "metadata": {
        "id": "RGoo99B_JA4N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01/30 | lr=0.00099729 | train_RMSE=0.112651 | eval_RMSE=0.101932 | patience=0/3 | time=507.59s\n",
            "Epoch 02/30 | lr=0.000989187 | train_RMSE=0.096564 | eval_RMSE=0.094963 | patience=0/3 | time=509.24s\n",
            "Epoch 03/30 | lr=0.000975778 | train_RMSE=0.091001 | eval_RMSE=0.091882 | patience=0/3 | time=509.09s\n",
            "Epoch 04/30 | lr=0.000957212 | train_RMSE=0.086605 | eval_RMSE=0.089332 | patience=0/3 | time=508.55s\n",
            "Epoch 05/30 | lr=0.000933691 | train_RMSE=0.083199 | eval_RMSE=0.089521 | patience=1/3 | time=508.98s\n",
            "Epoch 06/30 | lr=0.000905473 | train_RMSE=0.079440 | eval_RMSE=0.088686 | patience=2/3 | time=509.07s\n",
            "Epoch 07/30 | lr=0.000872868 | train_RMSE=0.075826 | eval_RMSE=0.086161 | patience=0/3 | time=508.28s\n",
            "Epoch 08/30 | lr=0.000836232 | train_RMSE=0.071648 | eval_RMSE=0.086345 | patience=1/3 | time=508.49s\n",
            "Epoch 09/30 | lr=0.000795967 | train_RMSE=0.066771 | eval_RMSE=0.086189 | patience=2/3 | time=509.23s\n",
            "Epoch 10/30 | lr=0.000752515 | train_RMSE=0.061460 | eval_RMSE=0.087637 | patience=3/3 | time=509.05s\n"
          ]
        }
      ],
      "source": [
        "epochs_ran3 = train_loop(\n",
        "    model3,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=30,\n",
        "    patience=3,\n",
        "    min_delta=1e-3,\n",
        "    total_steps=total_steps,\n",
        "    initial_lr=1e-3,\n",
        "    alpha=1e-2,\n",
        "    device=device,\n",
        "    criterion=criterion3,\n",
        "    optimizer=optimizer3,\n",
        "    scaler=scaler3,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JHmBtEHqIjFa",
      "metadata": {
        "id": "JHmBtEHqIjFa"
      },
      "source": [
        "##### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "Fs2FLwYrJC7m",
      "metadata": {
        "id": "Fs2FLwYrJC7m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet50 Test RMSE: 0.08638898185622608\n",
            "ResNet50 epochs: 10\n"
          ]
        }
      ],
      "source": [
        "model3.eval()\n",
        "\n",
        "test_sse = 0.0\n",
        "test_n = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "            preds = model3(xb)\n",
        "\n",
        "        diff = preds - yb\n",
        "        test_sse += float(torch.sum(diff * diff).detach().cpu().item())\n",
        "        test_n += yb.numel()\n",
        "\n",
        "test_rmse3 = math.sqrt(test_sse / max(1, test_n))\n",
        "print(\"ResNet50 Test RMSE:\", test_rmse3)\n",
        "print(\"ResNet50 epochs:\", epochs_ran3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "MPUqkIqqS_MR",
      "metadata": {
        "id": "MPUqkIqqS_MR"
      },
      "outputs": [],
      "source": [
        "# Cell for cleanup\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EWhl2Z_oImHn",
      "metadata": {
        "id": "EWhl2Z_oImHn"
      },
      "source": [
        "#### MobileNetV2 (pretrained transfer learning)\n",
        "For this model, we opted for a frozen backbone, to check how well a pretrained transfer learning model would perform. We use pretrained weights, keep them fixed and only train our new head.\n",
        "##### Model build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "9KViESkyJLpp",
      "metadata": {
        "id": "9KViESkyJLpp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            "  (1): MobileNetV2(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2dNormActivation(\n",
            "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "      )\n",
            "      (1): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (2): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (3): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (4): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (5): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (6): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (7): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (8): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (9): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (10): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (11): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (12): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (13): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (14): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (15): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (16): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (17): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (18): Conv2dNormActivation(\n",
            "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (classifier): Identity()\n",
            "  )\n",
            "  (2): Dropout(p=0.2, inplace=False)\n",
            "  (3): Linear(in_features=1280, out_features=37, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "weights = models.MobileNet_V2_Weights.IMAGENET1K_V1\n",
        "base = models.mobilenet_v2(weights=weights)\n",
        "\n",
        "# Freeze backbone\n",
        "for p in base.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# Remove classifier so backbone returns features [B, 1280, H', W']\n",
        "base.classifier = nn.Identity()\n",
        "\n",
        "# MobileNetV2 expects inputs normalized to [-1, 1] (for tensors in [0,1])\n",
        "to_mobilenetv2_range = Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "\n",
        "model4 = nn.Sequential(\n",
        "    to_mobilenetv2_range,\n",
        "    base,\n",
        "    nn.Dropout(p=0.2),\n",
        "    nn.Linear(1280, 37, bias=True),\n",
        ")\n",
        "\n",
        "model4 = model4.to(device)\n",
        "\n",
        "print(model4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "v7_K272ZIvNy",
      "metadata": {
        "id": "v7_K272ZIvNy"
      },
      "source": [
        "##### Compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "e1AjHRNfJSqA",
      "metadata": {
        "id": "e1AjHRNfJSqA"
      },
      "outputs": [],
      "source": [
        "criterion4 = nn.MSELoss()\n",
        "\n",
        "optimizer4 = torch.optim.AdamW(\n",
        "    (p for p in model4.parameters() if p.requires_grad),\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        ")\n",
        "\n",
        "def cosine_decay4(step: int, total_steps: int, initial_lr: float = 1e-3, alpha: float = 1e-2) -> float:\n",
        "    step = min(step, total_steps)\n",
        "    cosine = 0.5 * (1.0 + math.cos(math.pi * step / total_steps))\n",
        "    return initial_lr * (alpha + (1.0 - alpha) * cosine)\n",
        "\n",
        "def set_lr4(optimizer: torch.optim.Optimizer, lr: float) -> None:\n",
        "    for pg in optimizer.param_groups:\n",
        "        pg[\"lr\"] = lr\n",
        "\n",
        "@torch.no_grad()\n",
        "def rmse4(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
        "\n",
        "scaler4 = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B-AdObjgIxwJ",
      "metadata": {
        "id": "B-AdObjgIxwJ"
      },
      "source": [
        "##### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "-KXhRvcLJ9jh",
      "metadata": {
        "id": "-KXhRvcLJ9jh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01/30 | lr=0.00099729 | train_RMSE=0.191170 | eval_RMSE=0.177336 | patience=0/3 | time=80.44s\n",
            "Epoch 02/30 | lr=0.000989187 | train_RMSE=0.179655 | eval_RMSE=0.175076 | patience=0/3 | time=80.67s\n",
            "Epoch 03/30 | lr=0.000975778 | train_RMSE=0.180192 | eval_RMSE=0.164982 | patience=0/3 | time=81.03s\n",
            "Epoch 04/30 | lr=0.000957212 | train_RMSE=0.179274 | eval_RMSE=0.173387 | patience=1/3 | time=81.32s\n",
            "Epoch 05/30 | lr=0.000933691 | train_RMSE=0.178611 | eval_RMSE=0.174649 | patience=2/3 | time=80.38s\n",
            "Epoch 06/30 | lr=0.000905473 | train_RMSE=0.177965 | eval_RMSE=0.163579 | patience=0/3 | time=80.63s\n",
            "Epoch 07/30 | lr=0.000872868 | train_RMSE=0.177081 | eval_RMSE=0.164883 | patience=1/3 | time=80.64s\n",
            "Epoch 08/30 | lr=0.000836232 | train_RMSE=0.176379 | eval_RMSE=0.164790 | patience=2/3 | time=80.53s\n",
            "Epoch 09/30 | lr=0.000795967 | train_RMSE=0.175059 | eval_RMSE=0.162376 | patience=0/3 | time=80.57s\n",
            "Epoch 10/30 | lr=0.000752515 | train_RMSE=0.174052 | eval_RMSE=0.159796 | patience=0/3 | time=80.53s\n",
            "Epoch 11/30 | lr=0.00070635 | train_RMSE=0.172933 | eval_RMSE=0.167712 | patience=1/3 | time=80.55s\n",
            "Epoch 12/30 | lr=0.000657979 | train_RMSE=0.171641 | eval_RMSE=0.172959 | patience=2/3 | time=80.63s\n",
            "Epoch 13/30 | lr=0.000607933 | train_RMSE=0.170032 | eval_RMSE=0.158328 | patience=0/3 | time=80.39s\n",
            "Epoch 14/30 | lr=0.000556758 | train_RMSE=0.169320 | eval_RMSE=0.158185 | patience=1/3 | time=80.72s\n",
            "Epoch 15/30 | lr=0.000505017 | train_RMSE=0.167681 | eval_RMSE=0.165501 | patience=2/3 | time=80.67s\n",
            "Epoch 16/30 | lr=0.000453275 | train_RMSE=0.166243 | eval_RMSE=0.158897 | patience=3/3 | time=80.54s\n"
          ]
        }
      ],
      "source": [
        "epochs_ran4 = train_loop(\n",
        "    model4,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=30,\n",
        "    patience=3,\n",
        "    min_delta=1e-3,\n",
        "    total_steps=total_steps,\n",
        "    initial_lr=1e-3,\n",
        "    alpha=1e-2,\n",
        "    device=device,\n",
        "    criterion=criterion4,\n",
        "    optimizer=optimizer4,\n",
        "    scaler=scaler4,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YRPxreeqIzDt",
      "metadata": {
        "id": "YRPxreeqIzDt"
      },
      "source": [
        "##### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "1eb9zfsDJ_a7",
      "metadata": {
        "id": "1eb9zfsDJ_a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MobileNetV2 TL Test RMSE: 0.15793819170595588\n",
            "MobileNetV2 TL epochs: 16\n"
          ]
        }
      ],
      "source": [
        "model4.eval()\n",
        "\n",
        "test_sse = 0.0\n",
        "test_n = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "            preds = model4(xb)\n",
        "\n",
        "        diff = preds - yb\n",
        "        test_sse += float(torch.sum(diff * diff).detach().cpu().item())\n",
        "        test_n += yb.numel()\n",
        "\n",
        "test_rmse4 = math.sqrt(test_sse / max(1, test_n))\n",
        "print(\"MobileNetV2 TL Test RMSE:\", test_rmse4)\n",
        "print(\"MobileNetV2 TL epochs:\", epochs_ran4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "dbkJNMuBTAAv",
      "metadata": {
        "id": "dbkJNMuBTAAv"
      },
      "outputs": [],
      "source": [
        "# Cell for cleanup\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BICrfI1FOHVN",
      "metadata": {
        "id": "BICrfI1FOHVN"
      },
      "source": [
        "#### VGG16 (pretrained)\n",
        "##### Model build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "tj92kYjjOTMO",
      "metadata": {
        "id": "tj92kYjjOTMO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/user/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (2): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (3): Flatten(start_dim=1, end_dim=-1)\n",
            "  (4): Dropout(p=0.3, inplace=False)\n",
            "  (5): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (6): ReLU(inplace=True)\n",
            "  (7): Dropout(p=0.3, inplace=False)\n",
            "  (8): Linear(in_features=256, out_features=37, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "weights = models.VGG16_Weights.IMAGENET1K_V1\n",
        "base = models.vgg16(weights=weights)\n",
        "\n",
        "# Trainable backbone\n",
        "for p in base.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "# Use feature extractor part only (convs)\n",
        "features = base.features\n",
        "\n",
        "# ImageNet normalization for tensors in [0,1]\n",
        "imagenet_normalize = Normalize(\n",
        "    mean=(0.485, 0.456, 0.406),\n",
        "    std=(0.229, 0.224, 0.225),\n",
        ")\n",
        "\n",
        "model5 = nn.Sequential(\n",
        "    imagenet_normalize,\n",
        "    features,                       # [B, 512, H', W']\n",
        "    nn.AdaptiveAvgPool2d((1, 1)),   # [B, 512, 1, 1]\n",
        "    nn.Flatten(1),                  # [B, 512]\n",
        "    nn.Dropout(p=0.3),\n",
        "    nn.Linear(512, 256, bias=True),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(p=0.3),\n",
        "    nn.Linear(256, 37, bias=True),\n",
        ")\n",
        "\n",
        "model5 = model5.to(device)\n",
        "\n",
        "print(model5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbBghuKwOgr3",
      "metadata": {
        "id": "dbBghuKwOgr3"
      },
      "source": [
        "##### Compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "0dNU8U49OgY-",
      "metadata": {
        "id": "0dNU8U49OgY-"
      },
      "outputs": [],
      "source": [
        "criterion5 = nn.MSELoss()\n",
        "\n",
        "optimizer5 = torch.optim.AdamW(model5.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "def cosine_decay5(step: int, total_steps: int, initial_lr: float = 1e-3, alpha: float = 1e-2) -> float:\n",
        "    step = min(step, total_steps)\n",
        "    cosine = 0.5 * (1.0 + math.cos(math.pi * step / total_steps))\n",
        "    return initial_lr * (alpha + (1.0 - alpha) * cosine)\n",
        "\n",
        "def set_lr5(optimizer: torch.optim.Optimizer, lr: float) -> None:\n",
        "    for pg in optimizer.param_groups:\n",
        "        pg[\"lr\"] = lr\n",
        "\n",
        "@torch.no_grad()\n",
        "def rmse5(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
        "\n",
        "scaler5 = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YI3MzdwJOjXV",
      "metadata": {
        "id": "YI3MzdwJOjXV"
      },
      "source": [
        "##### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "n8-Qdz_1O7or",
      "metadata": {
        "id": "n8-Qdz_1O7or"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01/30 | lr=0.00099729 | train_RMSE=0.166857 | eval_RMSE=0.164871 | patience=0/3 | time=1003.41s\n",
            "Epoch 02/30 | lr=0.000989187 | train_RMSE=0.164141 | eval_RMSE=0.164962 | patience=1/3 | time=1002.38s\n",
            "Epoch 03/30 | lr=0.000975778 | train_RMSE=0.164006 | eval_RMSE=0.164722 | patience=2/3 | time=1004.14s\n",
            "Epoch 04/30 | lr=0.000957212 | train_RMSE=nan | eval_RMSE=nan | patience=3/3 | time=994.55s\n"
          ]
        }
      ],
      "source": [
        "epochs_ran5 = train_loop(\n",
        "    model5,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=30,\n",
        "    patience=3,\n",
        "    min_delta=1e-3,\n",
        "    total_steps=total_steps,\n",
        "    initial_lr=1e-3,\n",
        "    alpha=1e-2,\n",
        "    device=device,\n",
        "    criterion=criterion5,\n",
        "    optimizer=optimizer5,\n",
        "    scaler=scaler5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XVwcuC5BOlVh",
      "metadata": {
        "id": "XVwcuC5BOlVh"
      },
      "source": [
        "##### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "p8Q2BjjcO8yc",
      "metadata": {
        "id": "p8Q2BjjcO8yc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VGG16 Test RMSE: 0.16424842647203233\n",
            "VGG16 epochs: 4\n"
          ]
        }
      ],
      "source": [
        "model5.eval()\n",
        "\n",
        "test_sse = 0.0\n",
        "test_n = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "            preds = model5(xb)\n",
        "\n",
        "        diff = preds - yb\n",
        "        test_sse += float(torch.sum(diff * diff).detach().cpu().item())\n",
        "        test_n += yb.numel()\n",
        "\n",
        "test_rmse5 = math.sqrt(test_sse / max(1, test_n))\n",
        "print(\"VGG16 Test RMSE:\", test_rmse5)\n",
        "print(\"VGG16 epochs:\", epochs_ran5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "576941b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler5 = torch.amp.GradScaler(\"cuda\", enabled=False)\n",
        "\n",
        "optimizer5 = torch.optim.AdamW(model5.parameters(), lr=1e-4, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "fdd74ae0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01/30 | lr=9.9729e-05 | train_RMSE=0.164035 | eval_RMSE=0.164709 | patience=0/3 | time=997.93s\n",
            "Epoch 02/30 | lr=9.89187e-05 | train_RMSE=0.164010 | eval_RMSE=0.164712 | patience=1/3 | time=1001.59s\n",
            "Epoch 03/30 | lr=9.75778e-05 | train_RMSE=0.163960 | eval_RMSE=0.164711 | patience=2/3 | time=1001.09s\n",
            "Epoch 04/30 | lr=9.57212e-05 | train_RMSE=0.163946 | eval_RMSE=0.164703 | patience=3/3 | time=1001.57s\n"
          ]
        }
      ],
      "source": [
        "epochs_ran5 = train_loop(\n",
        "    model5,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=30,\n",
        "    patience=3,\n",
        "    min_delta=1e-3,\n",
        "    total_steps=total_steps,\n",
        "    initial_lr=1e-4,   # lowered\n",
        "    alpha=1e-2,\n",
        "    device=device,\n",
        "    criterion=criterion5,\n",
        "    optimizer=optimizer5,\n",
        "    scaler=scaler5,    # AMP off\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "bfa21e2e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VGG16 Test RMSE: 0.16409609247217463\n",
            "VGG16 epochs: 4\n"
          ]
        }
      ],
      "source": [
        "model5.eval()\n",
        "\n",
        "test_sse = 0.0\n",
        "test_n = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "            preds = model5(xb)\n",
        "\n",
        "        diff = preds - yb\n",
        "        test_sse += float(torch.sum(diff * diff).detach().cpu().item())\n",
        "        test_n += yb.numel()\n",
        "\n",
        "test_rmse5 = math.sqrt(test_sse / max(1, test_n))\n",
        "print(\"VGG16 Test RMSE:\", test_rmse5)\n",
        "print(\"VGG16 epochs:\", epochs_ran5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ece352_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
