{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a7191f46",
      "metadata": {
        "id": "a7191f46"
      },
      "source": [
        "# Neuro-Fuzzy Computing - Project - Fall 2025\n",
        "## Galaxy Zoo — Training\n",
        "\n",
        "In this notebook, we train and evaluate on the **training** portion of the Galaxy Zoo dataset.\n",
        "\n",
        "Dataset location (Drive): `MyDrive/galaxy-zoo-the-galaxy-challenge/`: includes the files `images_training_rev1.zip` and `training_solutions_rev1.zip`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ZXkCrsacWoK",
      "metadata": {
        "id": "7ZXkCrsacWoK"
      },
      "source": [
        "#### Inspecting the initial dataset location"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vc0okI5GXiko",
      "metadata": {
        "id": "vc0okI5GXiko"
      },
      "source": [
        "### Dataset inspection and preprocessing\n",
        "\n",
        "In the following cells we perform the essential preprocessing steps\n",
        "\n",
        "1. **Define data paths and parameters**\n",
        "   - Point to the processed training images folder: `images_training_rev1/`\n",
        "   - Point to the label file: `training_solutions_rev1.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8kPAa1SRIwef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kPAa1SRIwef",
        "outputId": "a1ee2f40-ba0b-4cd5-cae2-a1ec49b3afd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "img_dir exists: True\n",
            "csv_path exists: True\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "DATA_ROOT = Path.cwd()\n",
        "\n",
        "img_dir = DATA_ROOT / \"images_training_rev1\"\n",
        "csv_path = DATA_ROOT / \"training_solutions_rev1.csv\"\n",
        "\n",
        "print(\"img_dir exists:\", img_dir.is_dir())\n",
        "print(\"csv_path exists:\", csv_path.is_file())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4K6EFxJqdDdj",
      "metadata": {
        "id": "4K6EFxJqdDdj"
      },
      "source": [
        "2. **Check label to image consistency**\n",
        "   - Confirm the number of label rows matches the number of processed images\n",
        "   - If there is a mismatch, we report example GalaxyIDs whose image files are missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8YpWNd3ydH8t",
      "metadata": {
        "id": "8YpWNd3ydH8t"
      },
      "outputs": [],
      "source": [
        "# If this cell takes minutes to run, something went wrong with Colab finding the images, most likely due to their size. If that happens, restart session\n",
        "solutions_df = pd.read_csv(csv_path)\n",
        "\n",
        "# IDs of Galaxies are the labels of the column \"GalaxyID\"\n",
        "ids = solutions_df[\"GalaxyID\"].astype(str).tolist()\n",
        "\n",
        "# These labels must match the names of the files inside the folder \"images_training_424\"\n",
        "train_image_names = sorted([p.name for p in img_dir.glob(\"*.jpg\")])\n",
        "\n",
        "if len(ids) != len(train_image_names):\n",
        "    missing = []\n",
        "    name_set = set(train_image_names)\n",
        "    for gid in ids[:50]:\n",
        "        if f\"{gid}.jpg\" not in name_set:\n",
        "            missing.append(gid)\n",
        "    raise ValueError(f\"Label/image count mismatch: labels={len(ids)} images={len(train_image_names)}. Example missing IDs: {missing[:10]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "La2fbyZqk_Zl",
      "metadata": {
        "id": "La2fbyZqk_Zl"
      },
      "source": [
        "3. **Prepare inputs for a TensorFlow dataset**\n",
        "\n",
        "In this cell, we:\n",
        "   - Create `paths` (image filepaths) and `labels` (soft targets) from `training_solutions_rev1.csv`\n",
        "   - Define `load_image(path, y)`, which will be used later with `tf.data.Dataset.map(...)` to load/parse images **on demand**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8866f4b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "target_cols = [c for c in solutions_df.columns if c != \"GalaxyID\"]\n",
        "\n",
        "paths = (solutions_df[\"GalaxyID\"].astype(int).astype(str) + \".jpg\") \\\n",
        "    .apply(lambda fn: str(img_dir / fn)).to_numpy()\n",
        "\n",
        "labels = solutions_df[target_cols].to_numpy(dtype=np.float32)\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.Resize((424, 424), interpolation=transforms.InterpolationMode.LANCZOS),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def load_image(path: str, y):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    img = img_transform(img)  # float32, [0,1], shape [3,424,424]\n",
        "    y = torch.as_tensor(y, dtype=torch.float32)\n",
        "    return img, y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CcWh08yqiBLU",
      "metadata": {
        "id": "CcWh08yqiBLU"
      },
      "source": [
        "### Train/Val/Test split (80/10/10)\n",
        "\n",
        "We create our own 80/10/10 train/val/test split from the edited training set.\n",
        "\n",
        "We start from a dataset of `(filepath, target_vector)` pairs and we shuffle **once** with a fixed seed (`seed=42`, `reshuffle_each_iteration=False`) to get a reproducible, **fixed** random ordering\n",
        "\n",
        "Split by slicing the shuffled dataset:\n",
        "  - **Train:** first 80% of samples\n",
        "  - **Validation:** next 10%\n",
        "  - **Test:** final 10%\n",
        "\n",
        "Lastly, we apply `load_image` **after** the split so each subset loads/decodes images lazily and independently"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d992de45",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size: 61578\n",
            "Train: 49262\n",
            "Val: 6157\n",
            "Test: 6159\n"
          ]
        }
      ],
      "source": [
        "n_total = len(paths)\n",
        "n_train = int(0.8 * n_total)\n",
        "n_val   = int(0.1 * n_total)\n",
        "n_test  = n_total - n_train - n_val\n",
        "\n",
        "print(\"Dataset size:\", n_total)\n",
        "print(\"Train:\", n_train)\n",
        "print(\"Val:\", n_val)\n",
        "print(\"Test:\", n_test)\n",
        "\n",
        "# Shuffle ONCE (fixed order for reproducibility)\n",
        "g = torch.Generator().manual_seed(42)\n",
        "perm = torch.randperm(n_total, generator=g).numpy()\n",
        "\n",
        "paths_shuf  = paths[perm]\n",
        "labels_shuf = labels[perm]\n",
        "\n",
        "# Split (no images loaded yet)\n",
        "train_paths, train_labels = paths_shuf[:n_train], labels_shuf[:n_train]\n",
        "val_paths,   val_labels   = paths_shuf[n_train:n_train + n_val], labels_shuf[n_train:n_train + n_val]\n",
        "test_paths,  test_labels  = paths_shuf[n_train + n_val:], labels_shuf[n_train + n_val:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hIYiScOSj5nI",
      "metadata": {
        "id": "hIYiScOSj5nI"
      },
      "source": [
        "### Image loading pipeline (lazy + batched)\n",
        "\n",
        "To build the dataset, we:\n",
        "   - Convert the split datasets from `(filepath, target_vector)` into `(image_tensor, target_tensor)` using `map(load_image)`\n",
        "     - Images are read/decoded **on demand** with `tf.io.read_file` + `tf.io.decode_jpeg`\n",
        "     - Converted to `float32` in **[0, 1]** (and resized to 424×424 as a safety step)\n",
        "   - Optimize input throughput:\n",
        "     - **Train:** shuffle (per epoch) → batch → prefetch\n",
        "     - **Val/Test:** batch → prefetch\n",
        "\n",
        "Each dataset element is a **batch** `(image_tensor, target_tensor)` where:\n",
        "  - `image_tensor` has shape **(batch_size, 424, 424, 3)** (channels-last) in **[0, 1]**\n",
        "  - `target_tensor` has shape **(batch_size, 37)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9Uir0aPYzZII",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Uir0aPYzZII",
        "outputId": "745a0fdc-ae4b-4878-e015-f6048086377a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train batch x: torch.Size([16, 3, 424, 424]) torch.float32 y: torch.Size([16, 37]) torch.float32\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "class PathLabelDataset(Dataset):\n",
        "    def __init__(self, paths, labels):\n",
        "        self.paths = paths\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return load_image(self.paths[idx], self.labels[idx])\n",
        "\n",
        "train_dataset = PathLabelDataset(train_paths, train_labels)\n",
        "val_dataset   = PathLabelDataset(val_paths, val_labels)\n",
        "test_dataset  = PathLabelDataset(test_paths, test_labels)\n",
        "\n",
        "num_workers = max(0, (os.cpu_count() or 0) // 4 - 1)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=(num_workers > 0),\n",
        "    prefetch_factor=2 if num_workers > 0 else None,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=(num_workers > 0),\n",
        "    prefetch_factor=2 if num_workers > 0 else None,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=(num_workers > 0),\n",
        "    prefetch_factor=2 if num_workers > 0 else None,\n",
        ")\n",
        "\n",
        "# Estimate total steps (batches) for full training run\n",
        "steps_per_epoch = len(train_loader)\n",
        "total_steps = int(steps_per_epoch * 30)  # 30 = max epochs\n",
        "\n",
        "xb, yb = next(iter(train_loader))\n",
        "print(\"train batch x:\", xb.shape, xb.dtype, \"y:\", yb.shape, yb.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PJqOTcWOplDw",
      "metadata": {
        "id": "PJqOTcWOplDw"
      },
      "source": [
        "### Building our CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "nZd_Ydzmpnm3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "id": "nZd_Ydzmpnm3",
        "outputId": "fd42893a-6cd2-44cf-e369-d997a5562735"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU(inplace=True)\n",
            "  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Dropout2d(p=0.05, inplace=False)\n",
            "  (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): ReLU(inplace=True)\n",
            "  (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (15): Dropout2d(p=0.1, inplace=False)\n",
            "  (16): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (17): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (18): ReLU(inplace=True)\n",
            "  (19): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (21): ReLU(inplace=True)\n",
            "  (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (23): Dropout2d(p=0.15, inplace=False)\n",
            "  (24): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (25): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (26): ReLU(inplace=True)\n",
            "  (27): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (28): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (29): ReLU(inplace=True)\n",
            "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (31): Dropout2d(p=0.2, inplace=False)\n",
            "  (32): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (33): Flatten(start_dim=1, end_dim=-1)\n",
            "  (34): Linear(in_features=256, out_features=37, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    # Block 1 (3 -> 32) with 2 convs\n",
        "    nn.Conv2d(3, 32, kernel_size=3, padding=1, bias=True),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=True),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Dropout2d(p=0.05),\n",
        "\n",
        "    # Block 2 (32 -> 64) with 2 convs\n",
        "    nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=True),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=True),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Dropout2d(p=0.10),\n",
        "\n",
        "    # Block 3 (64 -> 128) with 2 convs\n",
        "    nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=True),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=True),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Dropout2d(p=0.15),\n",
        "\n",
        "    # Block 4 (128 -> 256) with 2 convs\n",
        "    nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=True),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=True),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Dropout2d(p=0.20),\n",
        "\n",
        "    # Global average pooling + 37-dim output\n",
        "    nn.AdaptiveAvgPool2d((1, 1)),\n",
        "    nn.Flatten(1),\n",
        "    nn.Linear(256, 37, bias=True),\n",
        ")\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T8LHtZktsC_s",
      "metadata": {
        "id": "T8LHtZktsC_s"
      },
      "source": [
        "### Optimizer, loss function and model compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "Z6NfIzqHkWRQ",
      "metadata": {
        "id": "Z6NfIzqHkWRQ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "def cosine_decay(step: int, total_steps: int, initial_lr: float = 1e-3, alpha: float = 1e-2) -> float:\n",
        "    step = min(step, total_steps)\n",
        "    cosine = 0.5 * (1.0 + math.cos(math.pi * step / total_steps))\n",
        "    return initial_lr * (alpha + (1.0 - alpha) * cosine)\n",
        "\n",
        "def set_lr(optimizer: torch.optim.Optimizer, lr: float) -> None:\n",
        "    for pg in optimizer.param_groups:\n",
        "        pg[\"lr\"] = lr\n",
        "\n",
        "@torch.no_grad()\n",
        "def rmse(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
        "\n",
        "scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DJBhN4TNtDti",
      "metadata": {
        "id": "DJBhN4TNtDti"
      },
      "source": [
        "### Defining the training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Eb5ZfncXtF2t",
      "metadata": {
        "id": "Eb5ZfncXtF2t"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import copy\n",
        "\n",
        "def get_current_lr(optimizer: torch.optim.Optimizer) -> float:\n",
        "    return float(optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "def train_loop(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs: int = 30,\n",
        "    patience: int = 3,\n",
        "    min_delta: float = 1e-3,\n",
        "    total_steps: int | None = None,\n",
        "    initial_lr: float = 1e-3,\n",
        "    alpha: float = 1e-2,\n",
        "    device: torch.device | None = None,\n",
        "    criterion=None,\n",
        "    optimizer=None,\n",
        "    scaler=None,\n",
        "):\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "    if criterion is None:\n",
        "        raise ValueError(\"criterion must be provided (e.g., nn.MSELoss()).\")\n",
        "    if optimizer is None:\n",
        "        raise ValueError(\"optimizer must be provided (e.g., torch.optim.AdamW(...)).\")\n",
        "    if scaler is None:\n",
        "        scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))\n",
        "\n",
        "    if total_steps is None:\n",
        "        total_steps = len(train_loader) * epochs\n",
        "\n",
        "    def cosine_decay(step: int) -> float:\n",
        "        s = min(step, total_steps)\n",
        "        cosine = 0.5 * (1.0 + math.cos(math.pi * s / total_steps))\n",
        "        return initial_lr * (alpha + (1.0 - alpha) * cosine)\n",
        "\n",
        "    def set_lr(lr: float) -> None:\n",
        "        for pg in optimizer.param_groups:\n",
        "            pg[\"lr\"] = lr\n",
        "\n",
        "    def rmse_sum_sse(pred: torch.Tensor, target: torch.Tensor) -> tuple[float, int]:\n",
        "        # returns (sum_squared_error, num_elements)\n",
        "        diff = pred - target\n",
        "        sse = float(torch.sum(diff * diff).detach().cpu().item())\n",
        "        n = target.numel()\n",
        "        return sse, n\n",
        "\n",
        "    best_val = float(\"inf\")\n",
        "    patience_ctr = 0\n",
        "    best_state = None\n",
        "    global_step = 0\n",
        "    last_epoch = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        t0 = time.time()\n",
        "        last_epoch = epoch\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_sse = 0.0\n",
        "        train_n = 0\n",
        "\n",
        "        for xb, yb in train_loader:\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "            set_lr(cosine_decay(global_step))\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            with torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "                preds = model(xb)\n",
        "                loss = criterion(preds, yb)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            sse, n = rmse_sum_sse(preds, yb)\n",
        "            train_sse += sse\n",
        "            train_n += n\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        train_rmse_val = math.sqrt(train_sse / max(1, train_n))\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        val_sse = 0.0\n",
        "        val_n = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb = xb.to(device, non_blocking=True)\n",
        "                yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "                with torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "                    preds = model(xb)\n",
        "\n",
        "                sse, n = rmse_sum_sse(preds, yb)\n",
        "                val_sse += sse\n",
        "                val_n += n\n",
        "\n",
        "        val_rmse_val = math.sqrt(val_sse / max(1, val_n))\n",
        "\n",
        "        lr_val = get_current_lr(optimizer)\n",
        "        dt = time.time() - t0\n",
        "\n",
        "        # Early stopping\n",
        "        improved = (best_val - val_rmse_val) > min_delta\n",
        "        if improved:\n",
        "            best_val = val_rmse_val\n",
        "            patience_ctr = 0\n",
        "            best_state = copy.deepcopy(model.state_dict())\n",
        "        else:\n",
        "            patience_ctr += 1\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:02d}/{epochs} | \"\n",
        "            f\"lr={lr_val:.6g} | \"\n",
        "            f\"train_RMSE={train_rmse_val:.6f} | \"\n",
        "            f\"eval_RMSE={val_rmse_val:.6f} | \"\n",
        "            f\"patience={patience_ctr}/{patience} | \"\n",
        "            f\"time={dt:.2f}s\"\n",
        "        )\n",
        "\n",
        "        if patience_ctr >= patience:\n",
        "            break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    return last_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cErZXrGOvEbg",
      "metadata": {
        "id": "cErZXrGOvEbg"
      },
      "source": [
        "### Training our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "lq_yj1hwvHON",
      "metadata": {
        "id": "lq_yj1hwvHON"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01/30 | lr=0.00099729 | train_RMSE=0.160046 | eval_RMSE=0.154146 | patience=0/3 | time=376.53s\n",
            "Epoch 02/30 | lr=0.000989187 | train_RMSE=0.152481 | eval_RMSE=0.148057 | patience=0/3 | time=377.16s\n",
            "Epoch 03/30 | lr=0.000975778 | train_RMSE=0.146231 | eval_RMSE=0.139906 | patience=0/3 | time=376.41s\n",
            "Epoch 04/30 | lr=0.000957212 | train_RMSE=0.137463 | eval_RMSE=0.128491 | patience=0/3 | time=376.21s\n",
            "Epoch 05/30 | lr=0.000933691 | train_RMSE=0.129679 | eval_RMSE=0.124759 | patience=0/3 | time=376.21s\n",
            "Epoch 06/30 | lr=0.000905473 | train_RMSE=0.124608 | eval_RMSE=0.121008 | patience=0/3 | time=376.35s\n",
            "Epoch 07/30 | lr=0.000872868 | train_RMSE=0.120480 | eval_RMSE=0.115805 | patience=0/3 | time=376.42s\n",
            "Epoch 08/30 | lr=0.000836232 | train_RMSE=0.116749 | eval_RMSE=0.111439 | patience=0/3 | time=376.52s\n",
            "Epoch 09/30 | lr=0.000795967 | train_RMSE=0.113611 | eval_RMSE=0.109716 | patience=0/3 | time=376.53s\n",
            "Epoch 10/30 | lr=0.000752515 | train_RMSE=0.110993 | eval_RMSE=0.107231 | patience=0/3 | time=376.57s\n",
            "Epoch 11/30 | lr=0.00070635 | train_RMSE=0.108963 | eval_RMSE=0.104874 | patience=0/3 | time=376.54s\n",
            "Epoch 12/30 | lr=0.000657979 | train_RMSE=0.107115 | eval_RMSE=0.102782 | patience=0/3 | time=376.45s\n",
            "Epoch 13/30 | lr=0.000607933 | train_RMSE=0.105605 | eval_RMSE=0.103871 | patience=1/3 | time=376.37s\n",
            "Epoch 14/30 | lr=0.000556758 | train_RMSE=0.104452 | eval_RMSE=0.100708 | patience=0/3 | time=376.55s\n",
            "Epoch 15/30 | lr=0.000505017 | train_RMSE=0.103038 | eval_RMSE=0.100742 | patience=1/3 | time=376.49s\n",
            "Epoch 16/30 | lr=0.000453275 | train_RMSE=0.101994 | eval_RMSE=0.099210 | patience=0/3 | time=376.53s\n",
            "Epoch 17/30 | lr=0.0004021 | train_RMSE=0.101096 | eval_RMSE=0.098887 | patience=1/3 | time=376.62s\n",
            "Epoch 18/30 | lr=0.000352053 | train_RMSE=0.100227 | eval_RMSE=0.098356 | patience=2/3 | time=376.67s\n",
            "Epoch 19/30 | lr=0.000303681 | train_RMSE=0.099334 | eval_RMSE=0.097416 | patience=0/3 | time=376.53s\n",
            "Epoch 20/30 | lr=0.000257515 | train_RMSE=0.098765 | eval_RMSE=0.098107 | patience=1/3 | time=376.50s\n",
            "Epoch 21/30 | lr=0.00021406 | train_RMSE=0.097897 | eval_RMSE=0.096711 | patience=2/3 | time=376.37s\n",
            "Epoch 22/30 | lr=0.000173793 | train_RMSE=0.097429 | eval_RMSE=0.096751 | patience=3/3 | time=376.35s\n"
          ]
        }
      ],
      "source": [
        "epochs_ran = train_loop(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=30,\n",
        "    patience=3,\n",
        "    min_delta=1e-3,\n",
        "    total_steps=total_steps,\n",
        "    initial_lr=1e-3,\n",
        "    alpha=1e-2,\n",
        "    device=device,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scaler=scaler,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PFUfJuPFxOtl",
      "metadata": {
        "id": "PFUfJuPFxOtl"
      },
      "source": [
        "### Evaluate on held-out test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nkPJqgQ6xLEO",
      "metadata": {
        "id": "nkPJqgQ6xLEO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test RMSE: 0.09789868925789266\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "test_sse = 0.0\n",
        "test_n = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "            preds = model(xb)\n",
        "\n",
        "        diff = preds - yb\n",
        "        test_sse += float(torch.sum(diff * diff).cpu().item())\n",
        "        test_n += yb.numel()\n",
        "\n",
        "test_rmse = math.sqrt(test_sse / max(1, test_n))\n",
        "print(\"Test RMSE:\", test_rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "eY6TqC9mSXdV",
      "metadata": {
        "id": "eY6TqC9mSXdV"
      },
      "outputs": [],
      "source": [
        "# Cell for cleanup\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ETngSJhzGhQC",
      "metadata": {
        "id": "ETngSJhzGhQC"
      },
      "source": [
        "## Comparison with other models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pr-qppS6GlCz",
      "metadata": {
        "id": "pr-qppS6GlCz"
      },
      "source": [
        "#### DenseNet\n",
        "\n",
        "##### Model build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "sv7dGOPBGr2O",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "sv7dGOPBGr2O",
        "outputId": "2fee6def-c76a-4373-997c-b7372becb8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /home/user/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): ImageClassification(\n",
            "      crop_size=[224]\n",
            "      resize_size=[256]\n",
            "      mean=[0.485, 0.456, 0.406]\n",
            "      std=[0.229, 0.224, 0.225]\n",
            "      interpolation=InterpolationMode.BILINEAR\n",
            "  )\n",
            "  (1): DenseNet(\n",
            "    (features): Sequential(\n",
            "      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu0): ReLU(inplace=True)\n",
            "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (denseblock1): _DenseBlock(\n",
            "        (denselayer1): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer2): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer3): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer4): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer5): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer6): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (transition1): _Transition(\n",
            "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      )\n",
            "      (denseblock2): _DenseBlock(\n",
            "        (denselayer1): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer2): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer3): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer4): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer5): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer6): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer7): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer8): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer9): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer10): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer11): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer12): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (transition2): _Transition(\n",
            "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      )\n",
            "      (denseblock3): _DenseBlock(\n",
            "        (denselayer1): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer2): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer3): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer4): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer5): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer6): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer7): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer8): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer9): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer10): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer11): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer12): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer13): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer14): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer15): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer16): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer17): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer18): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer19): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer20): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer21): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer22): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer23): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer24): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (transition3): _Transition(\n",
            "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      )\n",
            "      (denseblock4): _DenseBlock(\n",
            "        (denselayer1): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer2): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer3): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer4): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer5): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer6): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer7): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer8): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer9): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer10): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer11): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer12): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer13): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer14): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer15): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "        (denselayer16): _DenseLayer(\n",
            "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu1): ReLU(inplace=True)\n",
            "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu2): ReLU(inplace=True)\n",
            "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (classifier): Identity()\n",
            "  )\n",
            "  (2): Linear(in_features=1024, out_features=37, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "\n",
        "weights = models.DenseNet121_Weights.IMAGENET1K_V1\n",
        "base = models.densenet121(weights=weights)\n",
        "\n",
        "# Use as a feature extractor (remove classifier)\n",
        "base.classifier = nn.Identity()\n",
        "\n",
        "model2 = nn.Sequential(\n",
        "    weights.transforms(),      # handles resize/crop if needed + ImageNet normalization\n",
        "    base,                      # outputs [B, 1024]\n",
        "    nn.Linear(1024, 37, bias=True),\n",
        ")\n",
        "\n",
        "model2 = model2.to(device)\n",
        "\n",
        "print(model2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m6ci9DguH7OE",
      "metadata": {
        "id": "m6ci9DguH7OE"
      },
      "source": [
        "##### Compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "NJPBQ6-EH9gC",
      "metadata": {
        "id": "NJPBQ6-EH9gC"
      },
      "outputs": [],
      "source": [
        "model2 = model2.to(device)\n",
        "\n",
        "criterion2 = nn.MSELoss()\n",
        "\n",
        "optimizer2 = torch.optim.AdamW(model2.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "def cosine_decay2(step: int, total_steps: int, initial_lr: float = 1e-3, alpha: float = 1e-2) -> float:\n",
        "    step = min(step, total_steps)\n",
        "    cosine = 0.5 * (1.0 + math.cos(math.pi * step / total_steps))\n",
        "    return initial_lr * (alpha + (1.0 - alpha) * cosine)\n",
        "\n",
        "def set_lr2(optimizer: torch.optim.Optimizer, lr: float) -> None:\n",
        "    for pg in optimizer.param_groups:\n",
        "        pg[\"lr\"] = lr\n",
        "\n",
        "@torch.no_grad()\n",
        "def rmse2(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
        "\n",
        "scaler2 = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9i6tUumEIAnV",
      "metadata": {
        "id": "9i6tUumEIAnV"
      },
      "source": [
        "##### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "816e45cd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01/30 | lr=0.00099729 | train_RMSE=0.123484 | eval_RMSE=0.104466 | patience=0/3 | time=163.39s\n",
            "Epoch 02/30 | lr=0.000989187 | train_RMSE=0.104444 | eval_RMSE=0.100183 | patience=0/3 | time=162.76s\n",
            "Epoch 03/30 | lr=0.000975778 | train_RMSE=0.098061 | eval_RMSE=0.098982 | patience=0/3 | time=162.53s\n",
            "Epoch 04/30 | lr=0.000957212 | train_RMSE=0.092934 | eval_RMSE=0.092127 | patience=0/3 | time=163.21s\n",
            "Epoch 05/30 | lr=0.000933691 | train_RMSE=0.088679 | eval_RMSE=0.091321 | patience=1/3 | time=162.22s\n",
            "Epoch 06/30 | lr=0.000905473 | train_RMSE=0.085375 | eval_RMSE=0.087067 | patience=0/3 | time=162.51s\n",
            "Epoch 07/30 | lr=0.000872868 | train_RMSE=0.082520 | eval_RMSE=0.086000 | patience=0/3 | time=162.94s\n",
            "Epoch 08/30 | lr=0.000836232 | train_RMSE=0.080091 | eval_RMSE=0.084653 | patience=0/3 | time=162.55s\n",
            "Epoch 09/30 | lr=0.000795967 | train_RMSE=0.077301 | eval_RMSE=0.090185 | patience=1/3 | time=162.86s\n",
            "Epoch 10/30 | lr=0.000752515 | train_RMSE=0.074780 | eval_RMSE=0.086159 | patience=2/3 | time=162.63s\n",
            "Epoch 11/30 | lr=0.00070635 | train_RMSE=0.071841 | eval_RMSE=0.085086 | patience=3/3 | time=162.73s\n"
          ]
        }
      ],
      "source": [
        "epochs_ran2 = train_loop(\n",
        "    model2,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=30,\n",
        "    patience=3,\n",
        "    min_delta=1e-3,\n",
        "    total_steps=total_steps,\n",
        "    initial_lr=1e-3,\n",
        "    alpha=1e-2,\n",
        "    device=device,\n",
        "    criterion=criterion2,\n",
        "    optimizer=optimizer2,\n",
        "    scaler=scaler2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PTM07DDPIHES",
      "metadata": {
        "id": "PTM07DDPIHES"
      },
      "source": [
        "##### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iAj3xFyLIK_R",
      "metadata": {
        "id": "iAj3xFyLIK_R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DenseNet Test RMSE: 0.0847407106771224\n",
            "DenseNet epochs: 11\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "model2.eval()\n",
        "\n",
        "test_sse = 0.0\n",
        "test_n = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "            preds = model2(xb)\n",
        "\n",
        "        diff = preds - yb\n",
        "        test_sse += float(torch.sum(diff * diff).detach().cpu().item())\n",
        "        test_n += yb.numel()\n",
        "\n",
        "test_rmse2 = math.sqrt(test_sse / max(1, test_n))\n",
        "print(\"DenseNet Test RMSE:\", test_rmse2)\n",
        "print(\"DenseNet epochs:\", epochs_ran2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "R1CrVVmkTEMY",
      "metadata": {
        "id": "R1CrVVmkTEMY"
      },
      "outputs": [],
      "source": [
        "# Cell for cleanup\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B8Cv6GieIRPE",
      "metadata": {
        "id": "B8Cv6GieIRPE"
      },
      "source": [
        "#### ResNet\n",
        "##### Model build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "hztEfsKwIVXl",
      "metadata": {
        "id": "hztEfsKwIVXl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /home/user/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "  (1): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (2): Linear(in_features=2048, out_features=37, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torchvision.transforms import Normalize\n",
        "\n",
        "weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
        "base = models.resnet50(weights=weights)\n",
        "\n",
        "# Remove classification head so it outputs features\n",
        "base.fc = nn.Identity()\n",
        "\n",
        "imagenet_normalize = Normalize(\n",
        "    mean=(0.485, 0.456, 0.406),\n",
        "    std=(0.229, 0.224, 0.225),\n",
        ")\n",
        "\n",
        "model3 = nn.Sequential(\n",
        "    imagenet_normalize,      # expects float tensors in [0,1], shape [B,3,H,W]\n",
        "    base,                    # outputs [B, 2048]\n",
        "    nn.Linear(2048, 37, bias=True),\n",
        ")\n",
        "\n",
        "model3 = model3.to(device)\n",
        "\n",
        "print(model3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0g-8hUevIgSB",
      "metadata": {
        "id": "0g-8hUevIgSB"
      },
      "source": [
        "##### Compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "M1ghbesZI79p",
      "metadata": {
        "id": "M1ghbesZI79p"
      },
      "outputs": [],
      "source": [
        "criterion3 = nn.MSELoss()\n",
        "\n",
        "optimizer3 = torch.optim.AdamW(model3.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "def cosine_decay3(step: int, total_steps: int, initial_lr: float = 1e-3, alpha: float = 1e-2) -> float:\n",
        "    step = min(step, total_steps)\n",
        "    cosine = 0.5 * (1.0 + math.cos(math.pi * step / total_steps))\n",
        "    return initial_lr * (alpha + (1.0 - alpha) * cosine)\n",
        "\n",
        "def set_lr3(optimizer: torch.optim.Optimizer, lr: float) -> None:\n",
        "    for pg in optimizer.param_groups:\n",
        "        pg[\"lr\"] = lr\n",
        "\n",
        "@torch.no_grad()\n",
        "def rmse3(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
        "\n",
        "scaler3 = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j6OPEbqiIhyp",
      "metadata": {
        "id": "j6OPEbqiIhyp"
      },
      "source": [
        "##### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "RGoo99B_JA4N",
      "metadata": {
        "id": "RGoo99B_JA4N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01/30 | lr=0.00099729 | train_RMSE=0.112651 | eval_RMSE=0.101932 | patience=0/3 | time=507.59s\n",
            "Epoch 02/30 | lr=0.000989187 | train_RMSE=0.096564 | eval_RMSE=0.094963 | patience=0/3 | time=509.24s\n",
            "Epoch 03/30 | lr=0.000975778 | train_RMSE=0.091001 | eval_RMSE=0.091882 | patience=0/3 | time=509.09s\n",
            "Epoch 04/30 | lr=0.000957212 | train_RMSE=0.086605 | eval_RMSE=0.089332 | patience=0/3 | time=508.55s\n",
            "Epoch 05/30 | lr=0.000933691 | train_RMSE=0.083199 | eval_RMSE=0.089521 | patience=1/3 | time=508.98s\n",
            "Epoch 06/30 | lr=0.000905473 | train_RMSE=0.079440 | eval_RMSE=0.088686 | patience=2/3 | time=509.07s\n",
            "Epoch 07/30 | lr=0.000872868 | train_RMSE=0.075826 | eval_RMSE=0.086161 | patience=0/3 | time=508.28s\n",
            "Epoch 08/30 | lr=0.000836232 | train_RMSE=0.071648 | eval_RMSE=0.086345 | patience=1/3 | time=508.49s\n",
            "Epoch 09/30 | lr=0.000795967 | train_RMSE=0.066771 | eval_RMSE=0.086189 | patience=2/3 | time=509.23s\n",
            "Epoch 10/30 | lr=0.000752515 | train_RMSE=0.061460 | eval_RMSE=0.087637 | patience=3/3 | time=509.05s\n"
          ]
        }
      ],
      "source": [
        "epochs_ran3 = train_loop(\n",
        "    model3,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=30,\n",
        "    patience=3,\n",
        "    min_delta=1e-3,\n",
        "    total_steps=total_steps,\n",
        "    initial_lr=1e-3,\n",
        "    alpha=1e-2,\n",
        "    device=device,\n",
        "    criterion=criterion3,\n",
        "    optimizer=optimizer3,\n",
        "    scaler=scaler3,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JHmBtEHqIjFa",
      "metadata": {
        "id": "JHmBtEHqIjFa"
      },
      "source": [
        "##### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "Fs2FLwYrJC7m",
      "metadata": {
        "id": "Fs2FLwYrJC7m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet50 Test RMSE: 0.08638898185622608\n",
            "ResNet50 epochs: 10\n"
          ]
        }
      ],
      "source": [
        "model3.eval()\n",
        "\n",
        "test_sse = 0.0\n",
        "test_n = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "            preds = model3(xb)\n",
        "\n",
        "        diff = preds - yb\n",
        "        test_sse += float(torch.sum(diff * diff).detach().cpu().item())\n",
        "        test_n += yb.numel()\n",
        "\n",
        "test_rmse3 = math.sqrt(test_sse / max(1, test_n))\n",
        "print(\"ResNet50 Test RMSE:\", test_rmse3)\n",
        "print(\"ResNet50 epochs:\", epochs_ran3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "MPUqkIqqS_MR",
      "metadata": {
        "id": "MPUqkIqqS_MR"
      },
      "outputs": [],
      "source": [
        "# Cell for cleanup\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EWhl2Z_oImHn",
      "metadata": {
        "id": "EWhl2Z_oImHn"
      },
      "source": [
        "#### MobileNetV2 (pretrained transfer learning)\n",
        "For this model, we opted for a frozen backbone, to check how well a pretrained transfer learning model would perform. We use pretrained weights, keep them fixed and only train our new head.\n",
        "##### Model build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "9KViESkyJLpp",
      "metadata": {
        "id": "9KViESkyJLpp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            "  (1): MobileNetV2(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2dNormActivation(\n",
            "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "      )\n",
            "      (1): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (2): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (3): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (4): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
            "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (5): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (6): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (7): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (8): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (9): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (10): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (11): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (12): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (13): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (14): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (15): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (16): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (17): InvertedResidual(\n",
            "        (conv): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (18): Conv2dNormActivation(\n",
            "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (classifier): Identity()\n",
            "  )\n",
            "  (2): Dropout(p=0.2, inplace=False)\n",
            "  (3): Linear(in_features=1280, out_features=37, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "weights = models.MobileNet_V2_Weights.IMAGENET1K_V1\n",
        "base = models.mobilenet_v2(weights=weights)\n",
        "\n",
        "# Freeze backbone\n",
        "for p in base.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# Remove classifier so backbone returns features [B, 1280, H', W']\n",
        "base.classifier = nn.Identity()\n",
        "\n",
        "# MobileNetV2 expects inputs normalized to [-1, 1] (for tensors in [0,1])\n",
        "to_mobilenetv2_range = Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "\n",
        "model4 = nn.Sequential(\n",
        "    to_mobilenetv2_range,\n",
        "    base,\n",
        "    nn.Dropout(p=0.2),\n",
        "    nn.Linear(1280, 37, bias=True),\n",
        ")\n",
        "\n",
        "model4 = model4.to(device)\n",
        "\n",
        "print(model4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "v7_K272ZIvNy",
      "metadata": {
        "id": "v7_K272ZIvNy"
      },
      "source": [
        "##### Compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "e1AjHRNfJSqA",
      "metadata": {
        "id": "e1AjHRNfJSqA"
      },
      "outputs": [],
      "source": [
        "criterion4 = nn.MSELoss()\n",
        "\n",
        "optimizer4 = torch.optim.AdamW(\n",
        "    (p for p in model4.parameters() if p.requires_grad),\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        ")\n",
        "\n",
        "def cosine_decay4(step: int, total_steps: int, initial_lr: float = 1e-3, alpha: float = 1e-2) -> float:\n",
        "    step = min(step, total_steps)\n",
        "    cosine = 0.5 * (1.0 + math.cos(math.pi * step / total_steps))\n",
        "    return initial_lr * (alpha + (1.0 - alpha) * cosine)\n",
        "\n",
        "def set_lr4(optimizer: torch.optim.Optimizer, lr: float) -> None:\n",
        "    for pg in optimizer.param_groups:\n",
        "        pg[\"lr\"] = lr\n",
        "\n",
        "@torch.no_grad()\n",
        "def rmse4(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
        "\n",
        "scaler4 = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B-AdObjgIxwJ",
      "metadata": {
        "id": "B-AdObjgIxwJ"
      },
      "source": [
        "##### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "-KXhRvcLJ9jh",
      "metadata": {
        "id": "-KXhRvcLJ9jh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01/30 | lr=0.00099729 | train_RMSE=0.191170 | eval_RMSE=0.177336 | patience=0/3 | time=80.44s\n",
            "Epoch 02/30 | lr=0.000989187 | train_RMSE=0.179655 | eval_RMSE=0.175076 | patience=0/3 | time=80.67s\n",
            "Epoch 03/30 | lr=0.000975778 | train_RMSE=0.180192 | eval_RMSE=0.164982 | patience=0/3 | time=81.03s\n",
            "Epoch 04/30 | lr=0.000957212 | train_RMSE=0.179274 | eval_RMSE=0.173387 | patience=1/3 | time=81.32s\n",
            "Epoch 05/30 | lr=0.000933691 | train_RMSE=0.178611 | eval_RMSE=0.174649 | patience=2/3 | time=80.38s\n",
            "Epoch 06/30 | lr=0.000905473 | train_RMSE=0.177965 | eval_RMSE=0.163579 | patience=0/3 | time=80.63s\n",
            "Epoch 07/30 | lr=0.000872868 | train_RMSE=0.177081 | eval_RMSE=0.164883 | patience=1/3 | time=80.64s\n",
            "Epoch 08/30 | lr=0.000836232 | train_RMSE=0.176379 | eval_RMSE=0.164790 | patience=2/3 | time=80.53s\n",
            "Epoch 09/30 | lr=0.000795967 | train_RMSE=0.175059 | eval_RMSE=0.162376 | patience=0/3 | time=80.57s\n",
            "Epoch 10/30 | lr=0.000752515 | train_RMSE=0.174052 | eval_RMSE=0.159796 | patience=0/3 | time=80.53s\n",
            "Epoch 11/30 | lr=0.00070635 | train_RMSE=0.172933 | eval_RMSE=0.167712 | patience=1/3 | time=80.55s\n",
            "Epoch 12/30 | lr=0.000657979 | train_RMSE=0.171641 | eval_RMSE=0.172959 | patience=2/3 | time=80.63s\n",
            "Epoch 13/30 | lr=0.000607933 | train_RMSE=0.170032 | eval_RMSE=0.158328 | patience=0/3 | time=80.39s\n",
            "Epoch 14/30 | lr=0.000556758 | train_RMSE=0.169320 | eval_RMSE=0.158185 | patience=1/3 | time=80.72s\n",
            "Epoch 15/30 | lr=0.000505017 | train_RMSE=0.167681 | eval_RMSE=0.165501 | patience=2/3 | time=80.67s\n",
            "Epoch 16/30 | lr=0.000453275 | train_RMSE=0.166243 | eval_RMSE=0.158897 | patience=3/3 | time=80.54s\n"
          ]
        }
      ],
      "source": [
        "epochs_ran4 = train_loop(\n",
        "    model4,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=30,\n",
        "    patience=3,\n",
        "    min_delta=1e-3,\n",
        "    total_steps=total_steps,\n",
        "    initial_lr=1e-3,\n",
        "    alpha=1e-2,\n",
        "    device=device,\n",
        "    criterion=criterion4,\n",
        "    optimizer=optimizer4,\n",
        "    scaler=scaler4,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YRPxreeqIzDt",
      "metadata": {
        "id": "YRPxreeqIzDt"
      },
      "source": [
        "##### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "1eb9zfsDJ_a7",
      "metadata": {
        "id": "1eb9zfsDJ_a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MobileNetV2 TL Test RMSE: 0.15793819170595588\n",
            "MobileNetV2 TL epochs: 16\n"
          ]
        }
      ],
      "source": [
        "model4.eval()\n",
        "\n",
        "test_sse = 0.0\n",
        "test_n = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "            preds = model4(xb)\n",
        "\n",
        "        diff = preds - yb\n",
        "        test_sse += float(torch.sum(diff * diff).detach().cpu().item())\n",
        "        test_n += yb.numel()\n",
        "\n",
        "test_rmse4 = math.sqrt(test_sse / max(1, test_n))\n",
        "print(\"MobileNetV2 TL Test RMSE:\", test_rmse4)\n",
        "print(\"MobileNetV2 TL epochs:\", epochs_ran4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "dbkJNMuBTAAv",
      "metadata": {
        "id": "dbkJNMuBTAAv"
      },
      "outputs": [],
      "source": [
        "# Cell for cleanup\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BICrfI1FOHVN",
      "metadata": {
        "id": "BICrfI1FOHVN"
      },
      "source": [
        "#### VGG16 (pretrained)\n",
        "##### Model build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "tj92kYjjOTMO",
      "metadata": {
        "id": "tj92kYjjOTMO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/user/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
            "  (1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (2): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (3): Flatten(start_dim=1, end_dim=-1)\n",
            "  (4): Dropout(p=0.3, inplace=False)\n",
            "  (5): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (6): ReLU(inplace=True)\n",
            "  (7): Dropout(p=0.3, inplace=False)\n",
            "  (8): Linear(in_features=256, out_features=37, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "weights = models.VGG16_Weights.IMAGENET1K_V1\n",
        "base = models.vgg16(weights=weights)\n",
        "\n",
        "# Trainable backbone\n",
        "for p in base.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "# Use feature extractor part only (convs)\n",
        "features = base.features\n",
        "\n",
        "# ImageNet normalization for tensors in [0,1]\n",
        "imagenet_normalize = Normalize(\n",
        "    mean=(0.485, 0.456, 0.406),\n",
        "    std=(0.229, 0.224, 0.225),\n",
        ")\n",
        "\n",
        "model5 = nn.Sequential(\n",
        "    imagenet_normalize,\n",
        "    features,                       # [B, 512, H', W']\n",
        "    nn.AdaptiveAvgPool2d((1, 1)),   # [B, 512, 1, 1]\n",
        "    nn.Flatten(1),                  # [B, 512]\n",
        "    nn.Dropout(p=0.3),\n",
        "    nn.Linear(512, 256, bias=True),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Dropout(p=0.3),\n",
        "    nn.Linear(256, 37, bias=True),\n",
        ")\n",
        "\n",
        "model5 = model5.to(device)\n",
        "\n",
        "print(model5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbBghuKwOgr3",
      "metadata": {
        "id": "dbBghuKwOgr3"
      },
      "source": [
        "##### Compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "0dNU8U49OgY-",
      "metadata": {
        "id": "0dNU8U49OgY-"
      },
      "outputs": [],
      "source": [
        "criterion5 = nn.MSELoss()\n",
        "\n",
        "optimizer5 = torch.optim.AdamW(model5.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "def cosine_decay5(step: int, total_steps: int, initial_lr: float = 1e-3, alpha: float = 1e-2) -> float:\n",
        "    step = min(step, total_steps)\n",
        "    cosine = 0.5 * (1.0 + math.cos(math.pi * step / total_steps))\n",
        "    return initial_lr * (alpha + (1.0 - alpha) * cosine)\n",
        "\n",
        "def set_lr5(optimizer: torch.optim.Optimizer, lr: float) -> None:\n",
        "    for pg in optimizer.param_groups:\n",
        "        pg[\"lr\"] = lr\n",
        "\n",
        "@torch.no_grad()\n",
        "def rmse5(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
        "\n",
        "scaler5 = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YI3MzdwJOjXV",
      "metadata": {
        "id": "YI3MzdwJOjXV"
      },
      "source": [
        "##### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "n8-Qdz_1O7or",
      "metadata": {
        "id": "n8-Qdz_1O7or"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01/30 | lr=0.00099729 | train_RMSE=0.166857 | eval_RMSE=0.164871 | patience=0/3 | time=1003.41s\n",
            "Epoch 02/30 | lr=0.000989187 | train_RMSE=0.164141 | eval_RMSE=0.164962 | patience=1/3 | time=1002.38s\n",
            "Epoch 03/30 | lr=0.000975778 | train_RMSE=0.164006 | eval_RMSE=0.164722 | patience=2/3 | time=1004.14s\n",
            "Epoch 04/30 | lr=0.000957212 | train_RMSE=nan | eval_RMSE=nan | patience=3/3 | time=994.55s\n"
          ]
        }
      ],
      "source": [
        "epochs_ran5 = train_loop(\n",
        "    model5,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=30,\n",
        "    patience=3,\n",
        "    min_delta=1e-3,\n",
        "    total_steps=total_steps,\n",
        "    initial_lr=1e-3,\n",
        "    alpha=1e-2,\n",
        "    device=device,\n",
        "    criterion=criterion5,\n",
        "    optimizer=optimizer5,\n",
        "    scaler=scaler5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XVwcuC5BOlVh",
      "metadata": {
        "id": "XVwcuC5BOlVh"
      },
      "source": [
        "##### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "p8Q2BjjcO8yc",
      "metadata": {
        "id": "p8Q2BjjcO8yc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VGG16 Test RMSE: 0.16424842647203233\n",
            "VGG16 epochs: 4\n"
          ]
        }
      ],
      "source": [
        "model5.eval()\n",
        "\n",
        "test_sse = 0.0\n",
        "test_n = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "            preds = model5(xb)\n",
        "\n",
        "        diff = preds - yb\n",
        "        test_sse += float(torch.sum(diff * diff).detach().cpu().item())\n",
        "        test_n += yb.numel()\n",
        "\n",
        "test_rmse5 = math.sqrt(test_sse / max(1, test_n))\n",
        "print(\"VGG16 Test RMSE:\", test_rmse5)\n",
        "print(\"VGG16 epochs:\", epochs_ran5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "576941b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler5 = torch.amp.GradScaler(\"cuda\", enabled=False)\n",
        "\n",
        "optimizer5 = torch.optim.AdamW(model5.parameters(), lr=1e-4, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "fdd74ae0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01/30 | lr=9.9729e-05 | train_RMSE=0.164035 | eval_RMSE=0.164709 | patience=0/3 | time=997.93s\n",
            "Epoch 02/30 | lr=9.89187e-05 | train_RMSE=0.164010 | eval_RMSE=0.164712 | patience=1/3 | time=1001.59s\n",
            "Epoch 03/30 | lr=9.75778e-05 | train_RMSE=0.163960 | eval_RMSE=0.164711 | patience=2/3 | time=1001.09s\n",
            "Epoch 04/30 | lr=9.57212e-05 | train_RMSE=0.163946 | eval_RMSE=0.164703 | patience=3/3 | time=1001.57s\n"
          ]
        }
      ],
      "source": [
        "epochs_ran5 = train_loop(\n",
        "    model5,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs=30,\n",
        "    patience=3,\n",
        "    min_delta=1e-3,\n",
        "    total_steps=total_steps,\n",
        "    initial_lr=1e-4,   # lowered\n",
        "    alpha=1e-2,\n",
        "    device=device,\n",
        "    criterion=criterion5,\n",
        "    optimizer=optimizer5,\n",
        "    scaler=scaler5,    # AMP off\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "bfa21e2e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VGG16 Test RMSE: 0.16409609247217463\n",
            "VGG16 epochs: 4\n"
          ]
        }
      ],
      "source": [
        "model5.eval()\n",
        "\n",
        "test_sse = 0.0\n",
        "test_n = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "            preds = model5(xb)\n",
        "\n",
        "        diff = preds - yb\n",
        "        test_sse += float(torch.sum(diff * diff).detach().cpu().item())\n",
        "        test_n += yb.numel()\n",
        "\n",
        "test_rmse5 = math.sqrt(test_sse / max(1, test_n))\n",
        "print(\"VGG16 Test RMSE:\", test_rmse5)\n",
        "print(\"VGG16 epochs:\", epochs_ran5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
