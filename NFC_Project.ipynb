{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c371300b",
   "metadata": {},
   "source": [
    "# Neuro-Fuzzy Computing - Project - Fall 2025\n",
    "## Galaxy Zoo — Training Setup\n",
    "\n",
    "This notebook trains and evaluates a neural network on the **training** portion of the Galaxy Zoo dataset:\n",
    "\n",
    "- Images: `galaxy-zoo-the-galaxy-challenge/images_training_rev1/`\n",
    "- Labels: `galaxy-zoo-the-galaxy-challenge/training_solutions_rev1.csv`\n",
    "\n",
    "> **Note:** This dataset is a *37-output regression* problem (probabilities from a decision tree), not a single-label classifier.\n",
    "\n",
    "Required file structure (Linux):\n",
    "```\n",
    "project_root/\n",
    "├── NFC_Project.ipynb\n",
    "└── galaxy-zoo-the-galaxy-challenge/\n",
    "    ├── images_training_rev1/\n",
    "    │   ├── 100008.jpg\n",
    "    │   ├── 100023.jpg\n",
    "    │   └── ...\n",
    "    ├── training_solutions_rev1.csv\n",
    "    └── resuts.csv\n",
    "```\n",
    "Notebook contents (high-level):\n",
    "1. Load and validate the dataset (paths, CSV schema, image availability).\n",
    "2. Build a PyTorch `Dataset` and `DataLoader` (with train/val/test split).\n",
    "3. Define and train a CNN on the training split.\n",
    "4. Evaluate on validation and held-out test splits (report regression metrics over 37 outputs).\n",
    "5. Record training time and inference time, and run hyperparameter sensitivity experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68512b78",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6373fda6",
   "metadata": {},
   "source": [
    "If any necesasry library is missing, create and run the following cell\n",
    "```\n",
    "%pip install numpy pandas pillow matplotlib scikit-learn torch torchvision --break-system-packages\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86280ba2",
   "metadata": {},
   "source": [
    "### Checking PyTortch compatibility with CUDA\n",
    "In this cell, we:\n",
    "1. Choose the compute device this notebook should use. It is opted to run on an NVIDIA GPU.\n",
    "2. Enable performance settings on our GPU.\n",
    "    Specifically, we:\n",
    "    - Let cuDNN search for the fastest convolution algorithms for our fixed input sizes (the supposed tradeoff is slightly less deterministic timing/behavior if input sizes vary, but we ensure the images are all sized 224x224).\n",
    "    - Allow TF32 math on supported NVIDIA GPUs for matmul/conv, which can significantly speed up training with usually negligible accuracy impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf27d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.10.0+cu128\n",
      "torch built CUDA: 12.8\n",
      "device: cuda\n",
      "GPU: NVIDIA GeForce RTX 5060 Laptop GPU\n",
      "compute capability: 12.0\n",
      "total VRAM (GiB): 7.53\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torch built CUDA:\", torch.version.cuda)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    # Performance knobs (safe defaults)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    print(f\"compute capability: {props.major}.{props.minor}\")\n",
    "    print(f\"total VRAM (GiB): {props.total_memory / (1024**3):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e418b",
   "metadata": {},
   "source": [
    "### Dataset inspection and preprocessing\n",
    "\n",
    "In the following cells we perform the essential preprocessing steps\n",
    "\n",
    "1. **Define dataset paths and parameters**\n",
    "   - Point to the raw training images folder: `images_training_rev1/`\n",
    "   - Point to the label file: `training_solutions_rev1.csv`\n",
    "   - Define an output folder for resized images: `images_training_224/`\n",
    "   - Set the target image size to `(224, 224)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a8d94bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from PIL import Image\n",
    "\n",
    "root = Path(\"galaxy-zoo-the-galaxy-challenge\")\n",
    "raw_img_dir = root / \"images_training_rev1\"\n",
    "csv_path = root / \"training_solutions_rev1.csv\"\n",
    "proc_img_dir = root / \"images_training_224\"\n",
    "size = (224, 224)   # Size of each image inside \"images_training_224\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a006e651",
   "metadata": {},
   "source": [
    "2. **Verifiy required inputs exist**\n",
    "   - Check that `images_training_rev1/` exists and contains `.jpg` files\n",
    "   - Check that `training_solutions_rev1.csv` exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399c3d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not raw_img_dir.is_dir():\n",
    "    raise FileNotFoundError(f\"Missing folder: {raw_img_dir.resolve()}\")\n",
    "if not csv_path.is_file():\n",
    "    raise FileNotFoundError(f\"Missing file: {csv_path.resolve()}\")\n",
    "\n",
    "proc_img_dir.mkdir(exist_ok=True)\n",
    "\n",
    "raw_files = sorted([p for p in raw_img_dir.iterdir() if p.suffix.lower() == \".jpg\"])\n",
    "if not raw_files:\n",
    "    raise FileNotFoundError(f\"No .jpg files found in: {raw_img_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ca9ee",
   "metadata": {},
   "source": [
    "3. **Offline preprocessing: resize images into a new folder**\n",
    "   - Create `images_training_224/` if it doesn’t exist\n",
    "   - If preprocessing is needed, we iterate through raw images and save a resized `(224, 224)` version into `images_training_224/`\n",
    "   - Uses **LANCZOS** resampling for ensure high quality resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4efbef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_proc = list(proc_img_dir.glob(\"*.jpg\"))\n",
    "if len(existing_proc) != len(raw_files):\n",
    "    for p in raw_files:\n",
    "        out = proc_img_dir / p.name\n",
    "        if out.exists():\n",
    "            continue\n",
    "        img = Image.open(p).convert(\"RGB\").resize(size, Image.Resampling.LANCZOS)\n",
    "        img.save(out, format=\"JPEG\", quality=95, optimize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c6a0f6",
   "metadata": {},
   "source": [
    "4. **Validate preprocessing results**\n",
    "   - Open each processed image and confirms its size is exactly `(224, 224)`\n",
    "   - Build a sorted list of processed training filenames for later consistency checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fd0af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in proc_img_dir.glob(\"*.jpg\"):\n",
    "    with Image.open(p) as img:\n",
    "        if img.size != size:\n",
    "            raise ValueError(f\"Processed image has wrong size {img.size}, expected {size}: {p.name}\")\n",
    "\n",
    "train_image_names = sorted([p.name for p in proc_img_dir.glob(\"*.jpg\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32d8a0",
   "metadata": {},
   "source": [
    "5. **Load and validate the label table**\n",
    "   - Read `training_solutions_rev1.csv` into a DataFrame\n",
    "   - Confirm a `GalaxyID` column exists\n",
    "   - Confirm there are exactly **37 target columns** (Galaxy Zoo probability outputs)\n",
    "   - Split labels into:\n",
    "     - `ids` (GalaxyIDs, used to locate images on disk)\n",
    "     - `labels` (a float32 NumPy array of shape `(N, 37)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb843035",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(csv_path)\n",
    "if \"GalaxyID\" not in labels_df.columns:\n",
    "    raise ValueError(\"training_solutions_rev1.csv must contain a 'GalaxyID' column\")\n",
    "\n",
    "target_cols = [c for c in labels_df.columns if c != \"GalaxyID\"]\n",
    "if len(target_cols) != 37:\n",
    "    raise ValueError(f\"Expected 37 target columns, found {len(target_cols)}\")\n",
    "\n",
    "labels_only = labels_df.drop(columns=[\"GalaxyID\"])\n",
    "labels = labels_only.astype(\"float32\").to_numpy()\n",
    "ids = labels_df[\"GalaxyID\"].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9840cf",
   "metadata": {},
   "source": [
    "6. **Check label to image consistency**\n",
    "   - Confirm the number of label rows matches the number of processed images\n",
    "   - If there is a mismatch, we report example GalaxyIDs whose image files are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c414984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ids) != len(train_image_names):\n",
    "    missing = []\n",
    "    name_set = set(train_image_names)\n",
    "    for gid in ids[:50]:\n",
    "        if f\"{gid}.jpg\" not in name_set:\n",
    "            missing.append(gid)\n",
    "    raise ValueError(f\"Label/image count mismatch: labels={len(ids)} images={len(train_image_names)}. Example missing IDs: {missing[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204ee38c",
   "metadata": {},
   "source": [
    "7. **Build a PyTorch dataset (lazy loading)**\n",
    "   - Define `GalaxyZooDataset`, which loads images **on demand** from `images_training_224/`\n",
    "   - Return one sample as `(image_tensor, target_tensor, GalaxyID)` where:\n",
    "     - `image_tensor` has shape `(3, 224, 224)` in `[0, 1]`\n",
    "     - `target_tensor` has shape `(37,)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c2e4421",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyZooDataset(Dataset):\n",
    "    def __init__(self, img_dir: Path, ids, labels):\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.ids = list(ids)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gid = self.ids[idx]\n",
    "        img = Image.open(self.img_dir / f\"{gid}.jpg\").convert(\"RGB\")\n",
    "        x = to_tensor(img)  # float32, (C,H,W), range [0,1]\n",
    "\n",
    "        # Normalize using ImageNet stats\n",
    "        mean = torch.tensor((0.485, 0.456, 0.406)).view(3, 1, 1)\n",
    "        std  = torch.tensor((0.229, 0.224, 0.225)).view(3, 1, 1)\n",
    "        x = (x - mean) / std\n",
    "\n",
    "        y = torch.from_numpy(self.labels[idx])\n",
    "        return x, y, gid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdebb8de",
   "metadata": {},
   "source": [
    "8. **Run a smoke test**\n",
    "   - Finally, read `dataset[0]` and print shapes + the GalaxyID to confirm everything is wired correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7d35fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) torch.Size([37]) 100008\n"
     ]
    }
   ],
   "source": [
    "dataset = GalaxyZooDataset(proc_img_dir, ids, labels)\n",
    "\n",
    "x, y, gid = dataset[0]\n",
    "print(x.shape, y.shape, gid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c0fa5",
   "metadata": {},
   "source": [
    "### Train/Validation/Test split + DataLoaders\n",
    "\n",
    "Notes:\n",
    "- Our train/validation/test split is **80/10/10** (80% training, 10% validation, 10% held-out test).\n",
    "- We **shuffle the training data** (`shuffle=True`) so batches are not formed in any fixed file/ID order. This reduces bias from accidental ordering in the dataset and improves SGD/Adam convergence by making successive mini-batches more representative of the overall distribution.\n",
    "- We train using **mini-batches** (size `BATCH_SIZE`) instead of loading all images at once. This is required for practical GPU training: it limits memory usage (VRAM) and enables efficient, stable gradient updates.\n",
    "- We use multiple **DataLoader workers** (`NUM_WORKERS`) so image reading and preprocessing (disk I/O + JPEG decoding + tensor conversion) happen in parallel in background processes. This helps keep the GPU fed with data and reduces idle time between batches, especially when the CPU or disk is a bottleneck.\n",
    "    - `pin_memory=True` can speed up CPU-to-GPU transfers by allocating page-locked host memory\n",
    "    - `persistent_workers=True` keeps worker processes alive across epochs to reduce startup overhead (effective when `NUM_WORKERS > 0`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57135246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes: 49262 6158 6158\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "indices = np.arange(len(dataset))\n",
    "train_idx, temp_idx = train_test_split(indices, test_size=0.20, random_state=42, shuffle=True)\n",
    "val_idx, test_idx   = train_test_split(temp_idx, test_size=0.50, random_state=42, shuffle=True)\n",
    "\n",
    "train_ds = Subset(dataset, train_idx)\n",
    "val_ds   = Subset(dataset, val_idx)\n",
    "test_ds  = Subset(dataset, test_idx)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "print(\"Sizes:\", len(train_ds), len(val_ds), len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f992ba61",
   "metadata": {},
   "source": [
    "### Our CNN models \n",
    "all having outputs of 37 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10fff16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN37(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=256, out_features=37, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as tvm\n",
    "\n",
    "class SimpleCNN37(nn.Module):\n",
    "    def __init__(self, out_dim=37):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(self.features(x))\n",
    "\n",
    "\n",
    "class BetterCNN37(nn.Module):\n",
    "    def __init__(self, out_dim=37):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1, bias=False), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1, bias=False), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.MaxPool2d(2), nn.Dropout2d(0.05),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1, bias=False), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1, bias=False), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d(2), nn.Dropout2d(0.10),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1, bias=False), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1, bias=False), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.MaxPool2d(2), nn.Dropout2d(0.15),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, padding=1, bias=False), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1, bias=False), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.MaxPool2d(2), nn.Dropout2d(0.20)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(self.features(x))\n",
    "\n",
    "\n",
    "def conv_bn_relu(in_ch, out_ch, k=3, p=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_ch, out_ch, kernel_size=k, padding=p, bias=False),\n",
    "        nn.BatchNorm2d(out_ch),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "\n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_ch, b1, b3, b5, bp):\n",
    "        super().__init__()\n",
    "        self.branch1 = conv_bn_relu(in_ch, b1, k=1, p=0)\n",
    "        self.branch3 = nn.Sequential(\n",
    "            conv_bn_relu(in_ch, b3, k=1, p=0),\n",
    "            conv_bn_relu(b3, b3, k=3, p=1),\n",
    "        )\n",
    "        self.branch5 = nn.Sequential(\n",
    "            conv_bn_relu(in_ch, b5, k=1, p=0),\n",
    "            conv_bn_relu(b5, b5, k=3, p=1),\n",
    "            conv_bn_relu(b5, b5, k=3, p=1),\n",
    "        )\n",
    "        self.branch_pool = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            conv_bn_relu(in_ch, bp, k=1, p=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.branch1(x), self.branch3(x), self.branch5(x), self.branch_pool(x)], dim=1)\n",
    "\n",
    "\n",
    "class InceptionCNN37(nn.Module):\n",
    "    def __init__(self, out_dim=37):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            conv_bn_relu(3, 32), conv_bn_relu(32, 32), nn.MaxPool2d(2),\n",
    "            conv_bn_relu(32, 64), conv_bn_relu(64, 64), nn.MaxPool2d(2),\n",
    "\n",
    "            InceptionBlock(64, b1=32, b3=32, b5=32, bp=32),  # out: 128\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            conv_bn_relu(128, 256), conv_bn_relu(256, 256),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(self.features(x))\n",
    "\n",
    "\n",
    "AVAILABLE_MODELS = [\n",
    "    \"simplecnn\",\n",
    "    \"bettercnn\",\n",
    "    \"inceptioncnn\",\n",
    "    \"resnet18\",\n",
    "    \"efficientnet_b0\",\n",
    "    \"efficientnet_b1\",\n",
    "    \"densenet121\",\n",
    "    \"vit_b_16\",\n",
    "    \"cvt\",\n",
    "]\n",
    "\n",
    "\n",
    "def make_model(name: str, out_dim: int = 37, pretrained: bool = True) -> nn.Module:\n",
    "    name = name.lower().strip()\n",
    "\n",
    "    if name == \"simplecnn\":\n",
    "        return SimpleCNN37(out_dim)\n",
    "\n",
    "    if name == \"bettercnn\":\n",
    "        return BetterCNN37(out_dim)\n",
    "\n",
    "    if name == \"inceptioncnn\":\n",
    "        return InceptionCNN37(out_dim)\n",
    "\n",
    "    if name == \"resnet18\":\n",
    "        weights = tvm.ResNet18_Weights.DEFAULT if pretrained else None\n",
    "        m = tvm.resnet18(weights=weights)\n",
    "        m.fc = nn.Linear(m.fc.in_features, out_dim)\n",
    "        return m\n",
    "\n",
    "    if name == \"efficientnet_b0\":\n",
    "        weights = tvm.EfficientNet_B0_Weights.DEFAULT if pretrained else None\n",
    "        m = tvm.efficientnet_b0(weights=weights)\n",
    "        m.classifier[1] = nn.Linear(m.classifier[1].in_features, out_dim)\n",
    "        return m\n",
    "\n",
    "    if name == \"efficientnet_b1\":\n",
    "        weights = tvm.EfficientNet_B1_Weights.DEFAULT if pretrained else None\n",
    "        m = tvm.efficientnet_b1(weights=weights)\n",
    "        m.classifier[1] = nn.Linear(m.classifier[1].in_features, out_dim)\n",
    "        return m\n",
    "\n",
    "    if name == \"densenet121\":\n",
    "        weights = tvm.DenseNet121_Weights.DEFAULT if pretrained else None\n",
    "        m = tvm.densenet121(weights=weights)\n",
    "        m.classifier = nn.Linear(m.classifier.in_features, out_dim)\n",
    "        return m\n",
    "\n",
    "    if name == \"vit_b_16\":\n",
    "        weights = tvm.ViT_B_16_Weights.DEFAULT if pretrained else None\n",
    "        m = tvm.vit_b_16(weights=weights)\n",
    "        m.heads.head = nn.Linear(m.heads.head.in_features, out_dim)\n",
    "        return m\n",
    "\n",
    "    if name == \"cvt\":\n",
    "        try:\n",
    "            import timm\n",
    "        except Exception as e:\n",
    "            raise ImportError(\"Model 'cvt' requires the 'timm' package (pip install timm).\") from e\n",
    "        return timm.create_model(\"cvt-13\", pretrained=pretrained, num_classes=out_dim)\n",
    "\n",
    "    raise ValueError(\n",
    "        f\"Unknown model name: '{name}'. Available models: {', '.join(AVAILABLE_MODELS)}\"\n",
    "    )\n",
    "\n",
    "\n",
    "MODEL_NAME = \"simplecnn\"\n",
    "model = make_model(MODEL_NAME, out_dim=37, pretrained=True).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d669ed40",
   "metadata": {},
   "source": [
    "### Loss + optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e33eead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "EPOCHS = 15\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-5)\n",
    "\n",
    "@torch.no_grad()\n",
    "def rmse_from_sse(sse: float, n: int) -> float:\n",
    "    return (sse / n) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c0423",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "Now with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99643be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | lr: 9.89e-04 | train RMSE 0.156452 | val RMSE 0.148932 | best 0.148932 | no_improve 0/2 | time 103.3s\n",
      "Epoch 02 | lr: 9.57e-04 | train RMSE 0.139484 | val RMSE 0.134007 | best 0.134007 | no_improve 0/2 | time 100.8s\n",
      "Epoch 03 | lr: 9.05e-04 | train RMSE 0.128461 | val RMSE 0.127830 | best 0.127830 | no_improve 0/2 | time 100.6s\n",
      "Epoch 04 | lr: 8.36e-04 | train RMSE 0.119848 | val RMSE 0.122059 | best 0.122059 | no_improve 0/2 | time 100.5s\n",
      "Epoch 05 | lr: 7.52e-04 | train RMSE 0.114063 | val RMSE 0.111102 | best 0.111102 | no_improve 0/2 | time 100.2s\n",
      "Epoch 06 | lr: 6.58e-04 | train RMSE 0.109975 | val RMSE 0.110199 | best 0.111102 | no_improve 1/2 | time 100.4s\n",
      "Epoch 07 | lr: 5.57e-04 | train RMSE 0.106943 | val RMSE 0.106770 | best 0.106770 | no_improve 0/2 | time 100.5s\n",
      "Epoch 08 | lr: 4.53e-04 | train RMSE 0.104284 | val RMSE 0.107549 | best 0.106770 | no_improve 1/2 | time 100.3s\n",
      "Epoch 09 | lr: 3.52e-04 | train RMSE 0.102514 | val RMSE 0.103238 | best 0.103238 | no_improve 0/2 | time 94.4s\n",
      "Epoch 10 | lr: 2.58e-04 | train RMSE 0.100825 | val RMSE 0.101991 | best 0.101991 | no_improve 0/2 | time 59.9s\n",
      "Epoch 11 | lr: 1.74e-04 | train RMSE 0.099532 | val RMSE 0.101224 | best 0.101991 | no_improve 1/2 | time 58.0s\n",
      "Epoch 12 | lr: 1.05e-04 | train RMSE 0.098363 | val RMSE 0.100714 | best 0.100714 | no_improve 0/2 | time 58.4s\n",
      "Epoch 13 | lr: 5.28e-05 | train RMSE 0.097454 | val RMSE 0.100691 | best 0.100714 | no_improve 1/2 | time 58.3s\n",
      "Epoch 14 | lr: 2.08e-05 | train RMSE 0.096838 | val RMSE 0.100372 | best 0.100714 | no_improve 2/2 | time 58.2s\n",
      "Early stopping triggered.\n",
      "Loaded best model weights from epoch with val RMSE: 0.10071424391827857\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "def run_epoch(model, loader, train: bool):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_sse = 0.0\n",
    "    total_n = 0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for x, y, _ in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        preds = model(x)\n",
    "        preds = torch.sigmoid(preds)    # Adding sigmoid to constrain outputs between 0 and 1\n",
    "        loss = criterion(preds, y)\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        batch_sse = torch.sum((preds - y) ** 2).item()\n",
    "        total_sse += batch_sse\n",
    "        total_n += y.numel()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "\n",
    "    avg_mse = total_loss / len(loader.dataset)\n",
    "    avg_rmse = rmse_from_sse(total_sse, total_n)\n",
    "    return avg_mse, avg_rmse\n",
    "\n",
    "patience = 2\n",
    "min_delta = 1e-3  # require at least this much improvement\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "best_state = None\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "    train_mse, train_rmse = run_epoch(model, train_loader, train=True)\n",
    "    val_mse, val_rmse     = run_epoch(model, val_loader,   train=False)\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    improved = (best_val - val_rmse) > min_delta\n",
    "    if improved:\n",
    "        best_val = val_rmse\n",
    "        best_state = copy.deepcopy(model.state_dict())\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | lr: {optimizer.param_groups[0]['lr']:.2e} | train RMSE {train_rmse:.6f} | val RMSE {val_rmse:.6f} \"\n",
    "        f\"| best {best_val:.6f} | no_improve {epochs_no_improve}/{patience} | time {dt:.1f}s\"\n",
    "    )\n",
    "\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    print(\"Loaded best model weights from epoch with val RMSE:\", best_val)\n",
    "\n",
    "#EPOCHS = 10\n",
    "#for epoch in range(1, EPOCHS + 1):\n",
    "#    t0 = time.time()\n",
    "#    train_mse, train_rmse = run_epoch(model, train_loader, train=True)\n",
    "#    val_mse, val_rmse     = run_epoch(model, val_loader,   train=False)\n",
    "#    dt = time.time() - t0\n",
    "#    print(f\"Epoch {epoch:02d} | train RMSE {train_rmse:.6f} | val RMSE {val_rmse:.6f} | time {dt:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ffccaf",
   "metadata": {},
   "source": [
    "### Evaluate on held-out test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0f08781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.10041120567714927\n"
     ]
    }
   ],
   "source": [
    "test_mse, test_rmse = run_epoch(model, test_loader, train=False)\n",
    "print(\"Test RMSE:\", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca1a840",
   "metadata": {},
   "source": [
    "### Append to `results.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dcd68ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.10041120567714927\n",
      "Wrote to: /home/user/Documents/Project/results.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "test_mse, test_rmse = run_epoch(model, test_loader, train=False)\n",
    "print(\"Test RMSE:\", test_rmse)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%m%d%H%M%S\")\n",
    "model_name = MODEL_NAME  # make sure you have this variable set\n",
    "results_path = Path(\"results.csv\")\n",
    "\n",
    "file_exists = results_path.exists()\n",
    "\n",
    "with results_path.open(\"a\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"timestamp\", \"model\", \"RMSE\"])\n",
    "    if not file_exists:\n",
    "        writer.writeheader()\n",
    "    writer.writerow({\n",
    "        \"timestamp\": timestamp,\n",
    "        \"model\": str(model_name),\n",
    "        \"RMSE\": float(test_rmse),\n",
    "    })\n",
    "\n",
    "print(\"Wrote to:\", results_path.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
